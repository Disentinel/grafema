# Joel Spolsky — Technical Implementation Plan for RFD-5

**Date:** 2026-02-13
**Task:** T2.1 Manifest + Snapshot Chain
**Estimated LOC:** ~600
**Estimated Tests:** ~30
**Status:** Detailed technical specification

---

## Executive Summary

This specification provides complete implementation details for the Manifest + Snapshot Chain system. It includes exact Rust struct definitions, function signatures, implementation algorithms with Big-O complexity analysis, and a step-by-step implementation roadmap.

**Core pattern:** Delta Lake transaction log + LSM manifest safety. Immutable manifests + atomic pointer swap = ACID commits.

---

## 1. Complete Data Structures

### 1.1 Manifest (Core Snapshot Descriptor)

```rust
/// Manifest: immutable snapshot descriptor.
///
/// Each manifest represents a consistent point-in-time view of the database.
/// Manifests are immutable after commit except for tags (which can be modified
/// atomically via separate write).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct Manifest {
    /// Manifest version (sequential, monotonic, gaps allowed after crash recovery)
    pub version: u64,

    /// Creation timestamp (Unix epoch seconds)
    pub created_at: u64,

    /// Active node segments in this snapshot
    pub node_segments: Vec<SegmentDescriptor>,

    /// Active edge segments in this snapshot
    pub edge_segments: Vec<SegmentDescriptor>,

    /// Optional tags for snapshot identification.
    /// Empty HashMap = no tags. Common tags:
    /// - "analysis_run": "success" | "failed"
    /// - "commit_sha": git commit hash
    /// - "build_number": CI build identifier
    #[serde(default)]
    pub tags: HashMap<String, String>,

    /// Pre-computed aggregate statistics
    pub stats: ManifestStats,

    /// Previous manifest version (None for first manifest, v1)
    /// Enables chain traversal without directory scanning.
    #[serde(skip_serializing_if = "Option::is_none")]
    pub parent_version: Option<u64>,
}
```

**Serde attributes:**
- `#[serde(default)]` on `tags`: If missing in old JSON, deserialize as empty HashMap
- `#[serde(skip_serializing_if = "Option::is_none")]` on `parent_version`: Omit field when None (cleaner JSON for v1 manifest)

**Invariants:**
- `version >= 1` (version 0 reserved for "no database")
- `created_at > 0` (Unix epoch start is 1970-01-01)
- `node_segments` and `edge_segments` can be empty (valid snapshot of empty database)
- `stats` must match sum of segment descriptors (validated in debug builds)

### 1.2 SegmentDescriptor (Segment Metadata + Zone Map)

```rust
/// Segment descriptor: file location + zone map summary.
///
/// Bridges from ephemeral SegmentMeta (returned by writer) to serializable
/// manifest format. Includes zone map data for query planning without opening segments.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq, Hash)]
pub struct SegmentDescriptor {
    /// Unique segment ID (globally monotonic within database)
    /// Generated by ManifestStore::next_segment_id()
    pub segment_id: u64,

    /// Relative path from db root: "segments/seg_000001_nodes.seg"
    pub file_path: String,

    /// Record count (nodes or edges)
    pub record_count: u64,

    /// File size in bytes
    pub byte_size: u64,

    /// Zone map: node types (empty for edge segments)
    /// Example: {"FUNCTION", "CLASS", "http:route"}
    #[serde(default, skip_serializing_if = "HashSet::is_empty")]
    pub node_types: HashSet<String>,

    /// Zone map: file paths (empty for edge segments)
    /// Example: {"src/main.rs", "src/lib.rs"}
    #[serde(default, skip_serializing_if = "HashSet::is_empty")]
    pub file_paths: HashSet<String>,

    /// Zone map: edge types (empty for node segments)
    /// Example: {"CALLS", "IMPORTS_FROM"}
    #[serde(default, skip_serializing_if = "HashSet::is_empty")]
    pub edge_types: HashSet<String>,
}

impl SegmentDescriptor {
    /// Convert SegmentMeta (from writer) to SegmentDescriptor (for manifest).
    ///
    /// Called after segment writer finishes:
    /// ```
    /// let meta = writer.finish(&mut file)?;
    /// let descriptor = SegmentDescriptor::from_meta(
    ///     store.next_segment_id(),
    ///     format!("segments/seg_{:06}_{}.seg", segment_id, segment_type),
    ///     meta,
    /// );
    /// ```
    pub fn from_meta(segment_id: u64, file_path: String, meta: SegmentMeta) -> Self {
        Self {
            segment_id,
            file_path,
            record_count: meta.record_count,
            byte_size: meta.byte_size,
            node_types: meta.node_types,
            file_paths: meta.file_paths,
            edge_types: meta.edge_types,
        }
    }

    /// Get segment type from descriptor (inferred from file_path or zone maps)
    pub fn segment_type(&self) -> SegmentType {
        if !self.node_types.is_empty() || !self.file_paths.is_empty() {
            SegmentType::Nodes
        } else {
            SegmentType::Edges
        }
    }

    /// Check if segment might contain records matching filters.
    /// Returns true if zone maps indicate potential match (false = definite miss).
    pub fn may_contain(&self, node_type: Option<&str>, file_path: Option<&str>, edge_type: Option<&str>) -> bool {
        if let Some(nt) = node_type {
            if !self.node_types.is_empty() && !self.node_types.contains(nt) {
                return false; // definite miss
            }
        }
        if let Some(fp) = file_path {
            if !self.file_paths.is_empty() && !self.file_paths.contains(fp) {
                return false; // definite miss
            }
        }
        if let Some(et) = edge_type {
            if !self.edge_types.is_empty() && !self.edge_types.contains(et) {
                return false; // definite miss
            }
        }
        true // possible match
    }
}
```

**Derive macros:**
- `PartialEq, Eq, Hash`: Enables use in HashSet for diff computation
- Equality based on `segment_id` (structural equality for tests)

### 1.3 ManifestStats (Aggregate Statistics)

```rust
/// Aggregate statistics for a manifest (sum of all segment descriptors).
///
/// Pre-computed to avoid scanning segment list on every query.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]
pub struct ManifestStats {
    /// Total node count across all node segments
    pub total_nodes: u64,

    /// Total edge count across all edge segments
    pub total_edges: u64,

    /// Number of node segments
    pub node_segment_count: u32,

    /// Number of edge segments
    pub edge_segment_count: u32,
}

impl ManifestStats {
    /// Compute stats from segment descriptors.
    pub fn from_segments(node_segments: &[SegmentDescriptor], edge_segments: &[SegmentDescriptor]) -> Self {
        Self {
            total_nodes: node_segments.iter().map(|s| s.record_count).sum(),
            total_edges: edge_segments.iter().map(|s| s.record_count).sum(),
            node_segment_count: node_segments.len() as u32,
            edge_segment_count: edge_segments.len() as u32,
        }
    }

    /// Validate stats match segment descriptors (debug builds only).
    #[cfg(debug_assertions)]
    pub fn validate(&self, node_segments: &[SegmentDescriptor], edge_segments: &[SegmentDescriptor]) {
        let expected = Self::from_segments(node_segments, edge_segments);
        debug_assert_eq!(self.total_nodes, expected.total_nodes, "stats mismatch: total_nodes");
        debug_assert_eq!(self.total_edges, expected.total_edges, "stats mismatch: total_edges");
        debug_assert_eq!(self.node_segment_count, expected.node_segment_count, "stats mismatch: node_segment_count");
        debug_assert_eq!(self.edge_segment_count, expected.edge_segment_count, "stats mismatch: edge_segment_count");
    }
}
```

### 1.4 CurrentPointer (Atomic Commit Marker)

```rust
/// Atomic pointer to current manifest version.
///
/// Stored in `current.json` at database root. Updated via atomic rename
/// (write to `current.json.tmp`, then rename to `current.json`).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct CurrentPointer {
    /// Current manifest version
    pub version: u64,
}

impl CurrentPointer {
    pub fn new(version: u64) -> Self {
        Self { version }
    }

    /// Read current pointer from database root.
    pub fn read_from(db_path: &Path) -> Result<Self> {
        let path = db_path.join("current.json");
        read_json(&path)
    }

    /// Write current pointer atomically.
    /// Uses temp file + rename pattern for atomicity.
    pub fn write_to(&self, db_path: &Path) -> Result<()> {
        let path = db_path.join("current.json");
        atomic_write_json(&path, self)?;
        fsync_directory(db_path)?; // Persist directory entry
        Ok(())
    }
}
```

### 1.5 SnapshotInfo (List View)

```rust
/// Lightweight snapshot information for list operations.
///
/// Does NOT include full segment lists (saves memory when listing thousands of snapshots).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SnapshotInfo {
    pub version: u64,
    pub created_at: u64,
    pub tags: HashMap<String, String>,
    pub stats: ManifestStats,
}

impl SnapshotInfo {
    /// Extract snapshot info from full manifest.
    pub fn from_manifest(manifest: &Manifest) -> Self {
        Self {
            version: manifest.version,
            created_at: manifest.created_at,
            tags: manifest.tags.clone(),
            stats: manifest.stats,
        }
    }
}
```

### 1.6 SnapshotDiff (Delta Between Versions)

```rust
/// Diff between two snapshots (from_version → to_version).
///
/// Computed via HashSet-based set difference on segment IDs.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SnapshotDiff {
    pub from_version: u64,
    pub to_version: u64,

    /// Node segments added in to_version (not in from_version)
    pub added_node_segments: Vec<SegmentDescriptor>,

    /// Node segments removed in to_version (in from_version, not in to_version)
    pub removed_node_segments: Vec<SegmentDescriptor>,

    /// Edge segments added in to_version
    pub added_edge_segments: Vec<SegmentDescriptor>,

    /// Edge segments removed in to_version
    pub removed_edge_segments: Vec<SegmentDescriptor>,

    /// Stats for from_version
    pub stats_from: ManifestStats,

    /// Stats for to_version
    pub stats_to: ManifestStats,
}

impl SnapshotDiff {
    /// Compute diff between two manifests.
    ///
    /// Algorithm: HashSet-based set difference.
    /// Complexity: O(S) where S = total segments in both manifests.
    pub fn compute(from: &Manifest, to: &Manifest) -> Self {
        let from_node_ids: HashSet<u64> = from.node_segments.iter().map(|s| s.segment_id).collect();
        let to_node_ids: HashSet<u64> = to.node_segments.iter().map(|s| s.segment_id).collect();

        let added_node_segments: Vec<SegmentDescriptor> = to.node_segments.iter()
            .filter(|s| !from_node_ids.contains(&s.segment_id))
            .cloned()
            .collect();

        let removed_node_segments: Vec<SegmentDescriptor> = from.node_segments.iter()
            .filter(|s| !to_node_ids.contains(&s.segment_id))
            .cloned()
            .collect();

        let from_edge_ids: HashSet<u64> = from.edge_segments.iter().map(|s| s.segment_id).collect();
        let to_edge_ids: HashSet<u64> = to.edge_segments.iter().map(|s| s.segment_id).collect();

        let added_edge_segments: Vec<SegmentDescriptor> = to.edge_segments.iter()
            .filter(|s| !from_edge_ids.contains(&s.segment_id))
            .cloned()
            .collect();

        let removed_edge_segments: Vec<SegmentDescriptor> = from.edge_segments.iter()
            .filter(|s| !to_edge_ids.contains(&s.segment_id))
            .cloned()
            .collect();

        Self {
            from_version: from.version,
            to_version: to.version,
            added_node_segments,
            removed_node_segments,
            added_edge_segments,
            removed_edge_segments,
            stats_from: from.stats,
            stats_to: to.stats,
        }
    }

    /// Number of segments changed (added + removed)
    pub fn change_count(&self) -> usize {
        self.added_node_segments.len() + self.removed_node_segments.len()
            + self.added_edge_segments.len() + self.removed_edge_segments.len()
    }

    /// Is this a no-op diff (no changes)?
    pub fn is_empty(&self) -> bool {
        self.change_count() == 0
    }
}
```

### 1.7 GCEntry (Garbage Collection Metadata)

```rust
/// Metadata about a segment file moved to gc/ directory.
///
/// Stored in `gc/gc_log.json` (append-only log of GC operations).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GCEntry {
    /// Segment ID that was garbage collected
    pub segment_id: u64,

    /// Original file path (before moving to gc/)
    pub original_path: String,

    /// New path in gc/ directory
    pub gc_path: String,

    /// Timestamp when moved to gc/ (Unix epoch seconds)
    pub collected_at: u64,

    /// Last manifest version that referenced this segment
    pub last_referenced_version: u64,
}
```

**Note:** GC log is optional Phase 1 feature (nice-to-have for debugging). Can be deferred if time-constrained.

---

## 2. ManifestStore API (Complete Function Signatures)

### 2.1 Main Structure

```rust
/// ManifestStore: manages manifest chain + current pointer + segment ID allocation.
///
/// NOT `Send + Sync` by default (contains PathBuf, cached Manifest).
/// For multi-threaded access, wrap in Arc<Mutex<ManifestStore>>.
pub struct ManifestStore {
    /// Database root path (None for ephemeral databases)
    db_path: Option<PathBuf>,

    /// Current manifest (cached in memory)
    current: Manifest,

    /// Next segment ID to allocate (thread-safe atomic counter)
    next_segment_id: AtomicU64,
}
```

### 2.2 Constructor Methods

```rust
impl ManifestStore {
    /// Open existing database (load current manifest).
    ///
    /// Algorithm:
    /// 1. Read current.json → get version
    /// 2. Load manifests/{version:06}.json
    /// 3. Initialize next_segment_id = max(all segment IDs) + 1
    ///
    /// Complexity: O(S) where S = segments in current manifest (for computing max ID)
    ///
    /// Errors:
    /// - Io: current.json or manifest file missing/unreadable
    /// - Json: manifest file corrupt
    /// - InvalidFormat: manifest validation failed
    pub fn open(db_path: &Path) -> Result<Self> {
        // Implementation in Phase 3
    }

    /// Create new database (write first manifest, version 1).
    ///
    /// Algorithm:
    /// 1. Create directories: manifests/, segments/, gc/
    /// 2. Create empty manifest (version=1, no segments)
    /// 3. Write manifests/000001.json
    /// 4. Write current.json → version 1
    /// 5. Initialize next_segment_id = 1
    ///
    /// Complexity: O(1)
    ///
    /// Errors:
    /// - Io: directory creation failed, file write failed
    /// - InvalidFormat: db_path already contains current.json
    pub fn create(db_path: &Path) -> Result<Self> {
        // Implementation in Phase 3
    }

    /// Create ephemeral store (in-memory, no disk writes).
    ///
    /// Used for:
    /// - Unit tests
    /// - Temporary analysis graphs
    /// - Query-only databases (no persistence)
    ///
    /// Complexity: O(1)
    pub fn ephemeral() -> Self {
        Self {
            db_path: None,
            current: Manifest {
                version: 1,
                created_at: current_timestamp(),
                node_segments: Vec::new(),
                edge_segments: Vec::new(),
                tags: HashMap::new(),
                stats: ManifestStats {
                    total_nodes: 0,
                    total_edges: 0,
                    node_segment_count: 0,
                    edge_segment_count: 0,
                },
                parent_version: None,
            },
            next_segment_id: AtomicU64::new(1),
        }
    }
}
```

### 2.3 Core Operations

```rust
impl ManifestStore {
    /// Get current manifest (borrowed reference).
    ///
    /// Complexity: O(1) (cached in memory)
    pub fn current(&self) -> &Manifest {
        &self.current
    }

    /// Create new manifest (not yet committed).
    ///
    /// Constructs manifest with:
    /// - version = current.version + 1
    /// - created_at = now
    /// - provided segments + tags
    /// - computed stats
    /// - parent_version = current.version
    ///
    /// Does NOT write to disk or update self.current (caller must call commit()).
    ///
    /// Complexity: O(S) where S = total segments (for computing stats)
    ///
    /// Errors:
    /// - InvalidFormat: segments contain duplicate segment_id
    pub fn create_manifest(
        &self,
        node_segments: Vec<SegmentDescriptor>,
        edge_segments: Vec<SegmentDescriptor>,
        tags: Option<HashMap<String, String>>,
    ) -> Result<Manifest> {
        // Validate: no duplicate segment IDs
        let mut seen_ids = HashSet::new();
        for seg in node_segments.iter().chain(edge_segments.iter()) {
            if !seen_ids.insert(seg.segment_id) {
                return Err(GraphError::InvalidFormat(
                    format!("Duplicate segment_id: {}", seg.segment_id)
                ));
            }
        }

        let version = self.current.version + 1;
        let stats = ManifestStats::from_segments(&node_segments, &edge_segments);

        Ok(Manifest {
            version,
            created_at: current_timestamp(),
            node_segments,
            edge_segments,
            tags: tags.unwrap_or_default(),
            stats,
            parent_version: Some(self.current.version),
        })
    }

    /// Atomically commit manifest version (swap current pointer).
    ///
    /// Algorithm:
    /// 1. Verify manifest.version == current.version + 1 (monotonicity check)
    /// 2. Write manifests/{version:06}.json
    /// 3. Fsync manifest file
    /// 4. Write current.json.tmp with new version
    /// 5. Fsync current.json.tmp
    /// 6. Atomic rename current.json.tmp → current.json
    /// 7. Fsync parent directory (persist directory entry)
    /// 8. Update self.current cache
    ///
    /// Complexity: O(S) where S = segments in manifest (for JSON serialization)
    ///
    /// Errors:
    /// - InvalidFormat: version not monotonic, manifest already committed
    /// - Io: file write or fsync failed
    /// - Json: serialization failed
    ///
    /// If ephemeral: only update self.current, no disk writes.
    pub fn commit(&mut self, manifest: Manifest) -> Result<()> {
        // Ephemeral: just update cache
        if self.db_path.is_none() {
            self.current = manifest;
            return Ok(());
        }

        let db_path = self.db_path.as_ref().unwrap();

        // Monotonicity check
        if manifest.version != self.current.version + 1 {
            return Err(GraphError::InvalidFormat(format!(
                "Cannot commit version {} (current: {})",
                manifest.version, self.current.version
            )));
        }

        // Write manifest file
        let manifest_path = manifest_file_path(db_path, manifest.version);
        atomic_write_json(&manifest_path, &manifest)?;

        // Write + rename current pointer
        let current_pointer = CurrentPointer::new(manifest.version);
        current_pointer.write_to(db_path)?;

        // Update cache
        self.current = manifest;

        Ok(())
    }

    /// Load specific manifest version from disk.
    ///
    /// Complexity: O(S) where S = segments in manifest (JSON deserialization)
    ///
    /// Errors:
    /// - Io: manifest file not found
    /// - Json: manifest file corrupt
    /// - InvalidFormat: manifest validation failed
    pub fn load_manifest(&self, version: u64) -> Result<Manifest> {
        if let Some(db_path) = &self.db_path {
            let path = manifest_file_path(db_path, version);
            let manifest: Manifest = read_json(&path)?;

            // Validate loaded manifest
            if manifest.version != version {
                return Err(GraphError::InvalidFormat(format!(
                    "Manifest version mismatch: expected {}, got {}",
                    version, manifest.version
                )));
            }

            #[cfg(debug_assertions)]
            manifest.stats.validate(&manifest.node_segments, &manifest.edge_segments);

            Ok(manifest)
        } else {
            // Ephemeral: only current manifest exists
            if version == self.current.version {
                Ok(self.current.clone())
            } else {
                Err(GraphError::InvalidFormat(format!(
                    "Ephemeral database has no version {}",
                    version
                )))
            }
        }
    }

    /// Allocate next segment ID (thread-safe).
    ///
    /// Uses atomic fetch_add for lock-free concurrency.
    ///
    /// Complexity: O(1)
    pub fn next_segment_id(&self) -> u64 {
        self.next_segment_id.fetch_add(1, Ordering::SeqCst)
    }
}
```

### 2.4 Snapshot Operations

```rust
impl ManifestStore {
    /// Find snapshot by tag (walks chain backwards from current).
    ///
    /// Algorithm:
    /// 1. Start at current manifest
    /// 2. If tags match → return version
    /// 3. If parent_version exists → load parent, repeat
    /// 4. If no match found → return None
    ///
    /// Complexity: O(N×S) where N = manifests traversed, S = avg segments per manifest
    /// Worst case: O(total_manifests × avg_segments)
    ///
    /// Errors:
    /// - Io: manifest file unreadable during traversal
    /// - Json: manifest file corrupt
    pub fn find_snapshot(&self, tag_key: &str, tag_value: &str) -> Result<Option<u64>> {
        let mut current = self.current.clone();

        loop {
            // Check if current manifest has matching tag
            if let Some(value) = current.tags.get(tag_key) {
                if value == tag_value {
                    return Ok(Some(current.version));
                }
            }

            // Walk to parent
            match current.parent_version {
                Some(parent_ver) => {
                    current = self.load_manifest(parent_ver)?;
                }
                None => return Ok(None), // reached v1, no match
            }
        }
    }

    /// List all snapshots (optionally filtered by tag key).
    ///
    /// Algorithm:
    /// 1. Scan manifests/ directory for *.json files
    /// 2. Parse filenames → version numbers
    /// 3. Load each manifest → extract SnapshotInfo
    /// 4. Filter by tag_key if provided
    /// 5. Sort by version ascending
    ///
    /// Complexity: O(M×S) where M = manifest files, S = avg segments per manifest
    ///
    /// Note: More efficient than chain traversal for listing all snapshots.
    ///
    /// Errors:
    /// - Io: directory read failed, manifest file unreadable
    /// - Json: manifest file corrupt
    pub fn list_snapshots(&self, filter_tag: Option<&str>) -> Result<Vec<SnapshotInfo>> {
        if self.db_path.is_none() {
            // Ephemeral: only current snapshot
            let info = SnapshotInfo::from_manifest(&self.current);
            if let Some(tag_key) = filter_tag {
                if self.current.tags.contains_key(tag_key) {
                    return Ok(vec![info]);
                } else {
                    return Ok(vec![]);
                }
            }
            return Ok(vec![info]);
        }

        let db_path = self.db_path.as_ref().unwrap();
        let manifests_dir = db_path.join("manifests");

        let mut infos = Vec::new();

        for entry in std::fs::read_dir(&manifests_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) != Some("json") {
                continue; // skip non-JSON files
            }

            let manifest: Manifest = read_json(&path)?;

            // Filter by tag_key if provided
            if let Some(tag_key) = filter_tag {
                if !manifest.tags.contains_key(tag_key) {
                    continue;
                }
            }

            infos.push(SnapshotInfo::from_manifest(&manifest));
        }

        // Sort by version ascending
        infos.sort_by_key(|info| info.version);

        Ok(infos)
    }

    /// Tag existing snapshot (modifies manifest file atomically).
    ///
    /// Algorithm:
    /// 1. Load manifest at version
    /// 2. Merge new tags into manifest.tags (overwrite existing keys)
    /// 3. Write manifest atomically (temp file + rename)
    ///
    /// Complexity: O(S) where S = segments in manifest (JSON serialization)
    ///
    /// Safety: Atomic write ensures no torn reads. Only tags are modified
    /// (segments/stats/version unchanged).
    ///
    /// Errors:
    /// - Io: manifest file not found or write failed
    /// - Json: manifest file corrupt or serialization failed
    pub fn tag_snapshot(&self, version: u64, tags: HashMap<String, String>) -> Result<()> {
        if self.db_path.is_none() {
            return Err(GraphError::InvalidFormat(
                "Cannot tag ephemeral snapshot".to_string()
            ));
        }

        let db_path = self.db_path.as_ref().unwrap();
        let manifest_path = manifest_file_path(db_path, version);

        // Load existing manifest
        let mut manifest: Manifest = read_json(&manifest_path)?;

        // Merge tags (new tags overwrite old)
        for (key, value) in tags {
            manifest.tags.insert(key, value);
        }

        // Write atomically
        atomic_write_json(&manifest_path, &manifest)?;

        Ok(())
    }

    /// Compute diff between two snapshots.
    ///
    /// Complexity: O(S) where S = total segments in both manifests
    ///
    /// Errors:
    /// - Io: manifest file not found
    /// - Json: manifest file corrupt
    pub fn diff_snapshots(&self, from_version: u64, to_version: u64) -> Result<SnapshotDiff> {
        let from = self.load_manifest(from_version)?;
        let to = self.load_manifest(to_version)?;
        Ok(SnapshotDiff::compute(&from, &to))
    }
}
```

### 2.5 Garbage Collection Operations

```rust
impl ManifestStore {
    /// Collect unreferenced segments (move to gc/ directory).
    ///
    /// Algorithm:
    /// 1. Identify retention window: [current - retention_versions, current]
    /// 2. Load all manifests in window → collect referenced segment IDs
    /// 3. Scan segments/ directory → find files not in referenced set
    /// 4. Move unreferenced files to gc/ directory (preserve filename)
    /// 5. Return list of moved file paths
    ///
    /// Complexity: O(R×S + F) where R = retention versions, S = avg segments,
    ///            F = files in segments/ directory
    ///
    /// Safety: Two-phase GC (collect → purge). If logic is wrong, files are
    /// in gc/ (recoverable), not deleted (permanent).
    ///
    /// Errors:
    /// - Io: directory read/write failed, file move failed
    /// - Json: manifest file corrupt
    pub fn gc_collect(&self, retention_versions: u64) -> Result<Vec<String>> {
        if self.db_path.is_none() {
            return Ok(Vec::new()); // ephemeral: no GC
        }

        let db_path = self.db_path.as_ref().unwrap();
        let segments_dir = db_path.join("segments");
        let gc_dir = db_path.join("gc");

        // Ensure gc/ directory exists
        std::fs::create_dir_all(&gc_dir)?;

        // Determine retention window
        let current_version = self.current.version;
        let min_version = current_version.saturating_sub(retention_versions);

        // Collect referenced segment IDs
        let mut referenced_ids = HashSet::new();

        for version in min_version..=current_version {
            match self.load_manifest(version) {
                Ok(manifest) => {
                    for seg in manifest.node_segments.iter().chain(manifest.edge_segments.iter()) {
                        referenced_ids.insert(seg.segment_id);
                    }
                }
                Err(GraphError::Io(e)) if e.kind() == std::io::ErrorKind::NotFound => {
                    // Gap in manifest versions (failed write) → skip
                    continue;
                }
                Err(e) => return Err(e), // other errors → propagate
            }
        }

        // Scan segments/ directory
        let mut moved = Vec::new();

        for entry in std::fs::read_dir(&segments_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) != Some("seg") {
                continue; // skip non-segment files
            }

            // Extract segment_id from filename: seg_{id:06}_{type}.seg
            if let Some(segment_id) = parse_segment_id_from_filename(path.file_name().unwrap().to_str().unwrap()) {
                if !referenced_ids.contains(&segment_id) {
                    // Move to gc/
                    let filename = path.file_name().unwrap();
                    let gc_path = gc_dir.join(filename);
                    std::fs::rename(&path, &gc_path)?;
                    moved.push(gc_path.to_string_lossy().to_string());
                }
            }
        }

        Ok(moved)
    }

    /// Purge files from gc/ directory (permanent deletion).
    ///
    /// Algorithm:
    /// 1. Scan gc/ directory
    /// 2. Delete all .seg files
    /// 3. Return count of deleted files
    ///
    /// Complexity: O(F) where F = files in gc/
    ///
    /// Safety: Only deletes files in gc/ (already unreferenced by collect()).
    ///
    /// Errors:
    /// - Io: directory read or file deletion failed
    pub fn gc_purge(&self) -> Result<usize> {
        if self.db_path.is_none() {
            return Ok(0); // ephemeral: no GC
        }

        let db_path = self.db_path.as_ref().unwrap();
        let gc_dir = db_path.join("gc");

        let mut deleted = 0;

        for entry in std::fs::read_dir(&gc_dir)? {
            let entry = entry?;
            let path = entry.path();

            if path.extension().and_then(|s| s.to_str()) != Some("seg") {
                continue; // skip non-segment files (e.g., gc_log.json)
            }

            std::fs::remove_file(&path)?;
            deleted += 1;
        }

        Ok(deleted)
    }
}
```

---

## 3. Helper Functions (File I/O)

### 3.1 Atomic Write with Fsync

```rust
/// Write JSON to file atomically via temp file + rename.
///
/// Algorithm:
/// 1. Write to {path}.tmp
/// 2. Fsync temp file (flush to disk)
/// 3. Atomic rename {path}.tmp → {path}
/// 4. Return success
///
/// Atomicity: Rename is atomic on POSIX (single syscall).
/// On Windows: rename is NOT atomic if target exists. Must use fs2 crate
/// or ReplaceFile API.
///
/// Complexity: O(N) where N = serialized JSON size
///
/// Errors:
/// - Io: file write failed, fsync failed, rename failed
/// - Json: serialization failed
fn atomic_write_json<T: Serialize>(path: &Path, data: &T) -> Result<()> {
    let temp_path = path.with_extension("tmp");

    // Write to temp file
    let mut file = File::create(&temp_path)?;
    serde_json::to_writer_pretty(&file, data)?;
    file.sync_all()?; // fsync before rename

    // Atomic rename
    std::fs::rename(&temp_path, path)?;

    Ok(())
}
```

**Why pretty print?** Manifests are debugging artifacts. Pretty JSON aids manual inspection. Cost: ~20% larger files, negligible for <5KB manifests.

### 3.2 Read JSON

```rust
/// Read JSON from file.
///
/// Complexity: O(N) where N = file size
///
/// Errors:
/// - Io: file not found or unreadable
/// - Json: invalid JSON or deserialization failed
fn read_json<T: DeserializeOwned>(path: &Path) -> Result<T> {
    let file = File::open(path)?;
    Ok(serde_json::from_reader(file)?)
}
```

### 3.3 Directory Fsync (Durability on Linux)

```rust
/// Fsync directory to persist directory entry changes.
///
/// Required after rename operations on ext4/XFS to ensure directory
/// metadata is flushed to disk.
///
/// Platform-specific:
/// - Linux: required for durability
/// - macOS: no-op (HFS+/APFS auto-persist directory metadata)
/// - Windows: no-op (NTFS auto-persist)
///
/// Complexity: O(1) (single fsync syscall)
///
/// Errors:
/// - Io: directory open or fsync failed
#[cfg(target_os = "linux")]
fn fsync_directory(path: &Path) -> Result<()> {
    let dir = File::open(path)?;
    dir.sync_all()?;
    Ok(())
}

#[cfg(not(target_os = "linux"))]
fn fsync_directory(_path: &Path) -> Result<()> {
    Ok(()) // no-op on macOS/Windows
}
```

### 3.4 Utility Functions

```rust
/// Get manifest file path: {db_path}/manifests/{version:06}.json
fn manifest_file_path(db_path: &Path, version: u64) -> PathBuf {
    db_path.join("manifests").join(format!("{:06}.json", version))
}

/// Parse segment ID from filename: seg_000123_nodes.seg → 123
fn parse_segment_id_from_filename(filename: &str) -> Option<u64> {
    // Pattern: seg_{id:06}_{type}.seg
    let parts: Vec<&str> = filename.split('_').collect();
    if parts.len() >= 3 && parts[0] == "seg" {
        parts[1].parse::<u64>().ok()
    } else {
        None
    }
}

/// Get current Unix timestamp (seconds since epoch)
fn current_timestamp() -> u64 {
    std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap()
        .as_secs()
}
```

---

## 4. Big-O Complexity Analysis

### 4.1 Read Operations

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| `open()` | O(S) | S = segments in current manifest (compute max ID) |
| `current()` | O(1) | Cached in memory |
| `load_manifest(v)` | O(S) | S = segments in manifest v (JSON parse) |
| `find_snapshot(tag)` | O(N×S) | N = versions traversed, S = avg segments |
| `list_snapshots()` | O(M×S) | M = total manifests, S = avg segments |
| `diff_snapshots(from, to)` | O(S) | S = total segments in both manifests |

### 4.2 Write Operations

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| `create()` | O(1) | Write empty manifest + current pointer |
| `create_manifest()` | O(S) | S = segments (compute stats, validate IDs) |
| `commit(manifest)` | O(S) | S = segments (JSON serialization) |
| `tag_snapshot(v)` | O(S) | S = segments in manifest v (rewrite JSON) |
| `next_segment_id()` | O(1) | Atomic fetch_add |

### 4.3 GC Operations

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| `gc_collect(retention)` | O(R×S + F) | R = retention versions, S = avg segments, F = files in segments/ |
| `gc_purge()` | O(F) | F = files in gc/ |

### 4.4 Space Complexity

| Data Structure | Size | Notes |
|---------------|------|-------|
| `Manifest` in memory | O(S) | S = segments (Vec<SegmentDescriptor>) |
| `Manifest` on disk | ~1-5 KB | JSON, 100 segments × ~30 bytes each + metadata |
| `CurrentPointer` | 20 bytes | JSON: `{"version": 12345}` |
| `ManifestStore` | O(S) | Cached current manifest |

### 4.5 Performance Targets (Phase 1)

- **Commit latency:** <10ms for 100-segment manifest on SSD
- **GC collect:** <1s for 1000 manifests with 100 segments each
- **List snapshots:** <500ms for 1000 manifests
- **Find by tag:** <200ms worst case (1000 manifests)

These are NOT hard requirements (no premature optimization), but ballpark targets to sanity-check algorithm choices.

---

## 5. Implementation Roadmap

### Phase 1: Data Structures + Serde (100 LOC, ~6 tests)

**File:** `storage_v2/manifest.rs`

**Tasks:**
1. Define all structs with serde derives:
   - `Manifest`, `SegmentDescriptor`, `ManifestStats`, `CurrentPointer`
   - `SnapshotInfo`, `SnapshotDiff`, `GCEntry`
2. Implement `SegmentDescriptor::from_meta()`
3. Implement `ManifestStats::from_segments()`
4. Implement `SnapshotDiff::compute()`

**Tests:**
- `test_manifest_serde_roundtrip`: Serialize → deserialize → identical
- `test_manifest_stats_computation`: Segments → stats matches
- `test_segment_descriptor_from_meta`: SegmentMeta → SegmentDescriptor
- `test_snapshot_diff_compute`: v1 → v2 diff correctness
- `test_segment_descriptor_may_contain`: Zone map filtering logic
- `test_manifest_serde_optional_fields`: tags, parent_version omitted/default

**Expected output:** All structs compile, serde works, basic helper methods implemented.

### Phase 2: File I/O Helpers (80 LOC, ~5 tests)

**File:** `storage_v2/manifest.rs` (add helper functions)

**Tasks:**
1. Implement `atomic_write_json()` with temp file + rename
2. Implement `read_json()`
3. Implement `fsync_directory()` (conditional compilation)
4. Implement `manifest_file_path()`, `parse_segment_id_from_filename()`, `current_timestamp()`

**Tests:**
- `test_atomic_write_json_creates_file`: Write → read → identical
- `test_atomic_write_json_pretty_format`: Verify pretty-printed JSON
- `test_read_json_missing_file`: Returns Io error
- `test_fsync_directory_no_error`: Call on temp dir, no crash
- `test_parse_segment_id_from_filename`: Various formats

**Expected output:** Atomic write works, directory fsync compiles on Linux/macOS/Windows.

### Phase 3: ManifestStore Core (150 LOC, ~8 tests)

**File:** `storage_v2/manifest.rs` (add ManifestStore impl)

**Tasks:**
1. Implement `ManifestStore::ephemeral()`
2. Implement `ManifestStore::create(db_path)`
3. Implement `ManifestStore::open(db_path)`
4. Implement `ManifestStore::create_manifest()`
5. Implement `ManifestStore::commit()`
6. Implement `ManifestStore::load_manifest()`
7. Implement `ManifestStore::next_segment_id()`
8. Implement `CurrentPointer::read_from()` and `CurrentPointer::write_to()`

**Tests:**
- `test_manifest_store_ephemeral`: Create ephemeral, verify no db_path
- `test_manifest_store_create_new_database`: Create → verify files exist
- `test_manifest_store_open_existing`: Create → close → reopen → same version
- `test_manifest_store_commit_sequential`: Create v1 → commit v2 → commit v3
- `test_manifest_store_commit_updates_current`: Commit → current() matches new version
- `test_manifest_store_commit_monotonicity_check`: Try commit v1 again → error
- `test_manifest_store_load_manifest`: Commit v2 → load v1 → correct segments
- `test_manifest_store_next_segment_id_increments`: Allocate 3 IDs → 1, 2, 3

**Expected output:** Can create database, commit manifests, reopen database. Atomic commit protocol works.

### Phase 4: Snapshot Operations (120 LOC, ~6 tests)

**File:** `storage_v2/manifest.rs` (extend ManifestStore impl)

**Tasks:**
1. Implement `ManifestStore::find_snapshot()`
2. Implement `ManifestStore::list_snapshots()`
3. Implement `ManifestStore::tag_snapshot()`
4. Implement `SnapshotInfo::from_manifest()`

**Tests:**
- `test_find_snapshot_by_tag`: Tag v2 → find → returns 2
- `test_find_snapshot_not_found`: Search nonexistent tag → None
- `test_list_snapshots_all`: Create 3 versions → list → 3 entries
- `test_list_snapshots_filtered_by_tag`: Tag v2, list with filter → only v2
- `test_tag_snapshot_persists`: Tag v1 → reopen → tag still present
- `test_tag_snapshot_overwrites_existing`: Tag twice → last value wins

**Expected output:** Can tag snapshots, find by tag, list all snapshots.

### Phase 5: Diff Computation (50 LOC, ~4 tests)

**File:** Already implemented in `SnapshotDiff::compute()` (Phase 1)

**Tasks:**
1. Add tests for diff computation edge cases

**Tests:**
- `test_diff_empty_to_populated`: v1 (0 segments) → v2 (3 segments)
- `test_diff_same_version`: v1 → v1 diff is empty
- `test_diff_mixed_changes`: v1 (3 segs) → v2 (2 removed, 3 added)
- `test_diff_stats_match`: Verify stats_from/stats_to correct

**Expected output:** Diff logic handles all edge cases correctly.

### Phase 6: Garbage Collection (120 LOC, ~5 tests)

**File:** `storage_v2/manifest.rs` (extend ManifestStore impl)

**Tasks:**
1. Implement `ManifestStore::gc_collect()`
2. Implement `ManifestStore::gc_purge()`

**Tests:**
- `test_gc_collect_unreferenced`: Create v1-v10, retention=3 → v1-v6 segments in gc/
- `test_gc_collect_preserves_referenced`: Retention=3 → v7-v10 segments untouched
- `test_gc_collect_handles_gaps`: v1, v3, v5 (missing v2, v4) → no crash
- `test_gc_purge_deletes_files`: Move 3 files to gc/ → purge → 3 deleted
- `test_gc_ephemeral_no_op`: Ephemeral store → gc_collect → returns empty vec

**Expected output:** GC correctly identifies unreferenced segments, two-phase collect/purge works.

### Phase 7: Integration Tests (80 LOC, ~6 tests)

**File:** `tests/integration/manifest_store_tests.rs`

**Tasks:**
1. End-to-end test: create → commit → reopen → verify
2. Crash simulation: kill mid-write → verify DB still opens
3. Concurrent reads: spawn reader thread, commit new manifest, verify reader sees old snapshot
4. Large manifest: 1000 segments → commit → reopen → verify
5. GC integration: create 100 versions → GC with retention → verify
6. Tag + diff workflow: tag multiple versions, find, diff, verify

**Tests:**
- `test_end_to_end_create_commit_reopen`
- `test_crash_simulation_partial_write`
- `test_concurrent_reader_isolation`
- `test_large_manifest_1000_segments`
- `test_gc_with_retention_policy`
- `test_tag_find_diff_workflow`

**Expected output:** All integration tests pass. System works end-to-end.

---

## 6. Open Design Decisions (Resolved)

### 6.1 Segment ID Allocation ✅

**Decision:** Sequential counter (`AtomicU64`).

**Rationale:**
- Simple, predictable, matches Delta Lake pattern
- No hash collisions (vs content-based IDs)
- Thread-safe via atomic operations
- O(1) allocation

**Alternatives considered:**
- Content hash (BLAKE3 of segment) → collision risk, expensive to compute
- Random UUID → harder to debug, no ordering

### 6.2 Directory Fsync ✅

**Decision:** Add `fsync_directory()` with conditional compilation.

**Rationale:**
- Required for durability on ext4/XFS (Linux)
- No-op on macOS/Windows (filesystems handle it)
- Minimal cost: 3 lines, <1ms overhead
- Avoids data loss on Linux crashes

**Implementation:**
```rust
#[cfg(target_os = "linux")]
fn fsync_directory(path: &Path) -> Result<()> { ... }

#[cfg(not(target_os = "linux"))]
fn fsync_directory(_path: &Path) -> Result<()> { Ok(()) }
```

### 6.3 Ephemeral Database Detection ✅

**Decision:** `db_path: Option<PathBuf>` (None = ephemeral).

**Rationale:**
- Cleaner API than explicit `ephemeral: bool` flag
- Rust idiomatic (Option for optional state)
- All file operations check `if self.db_path.is_none()` → early return

**Pattern:**
```rust
if self.db_path.is_none() {
    return Ok(()); // ephemeral: no-op
}
let db_path = self.db_path.as_ref().unwrap();
// ... proceed with disk writes
```

### 6.4 Manifest Cache ✅

**Decision:** Cache ONLY `current` manifest. No HashMap cache for old manifests.

**Rationale:**
- Phase 1: single-threaded, no concurrent access → cache unnecessary
- Premature optimization → skip for now
- Add TODO comment for future (T3.1 multi-threaded batch commits)

**Future optimization (T3.1+):**
```rust
// TODO: Add manifest cache for multi-threaded access
// manifest_cache: Arc<Mutex<HashMap<u64, Arc<Manifest>>>>
```

### 6.5 GC Retention Policy ✅

**Decision:** `retention_versions: u64` parameter (caller-specified).

**Rationale:**
- Flexible: tests can use retention=1, production can use retention=100
- No hardcoded constant → easier to tune per deployment
- Default recommendation: 10-20 versions (balances storage vs rollback capability)

**API:**
```rust
pub fn gc_collect(&self, retention_versions: u64) -> Result<Vec<String>>
```

**Suggested defaults (not enforced by Phase 1):**
- Development: `retention = 5` (keep last 5 snapshots)
- Production: `retention = 20` (keep last 20 snapshots, ~1 week if daily commits)
- CI/test: `retention = 1` (minimal storage)

---

## 7. What NOT To Do (Anti-Patterns)

### 7.1 Deferred to Later Tasks (DO NOT IMPLEMENT)

These features are mentioned in architecture docs but NOT part of T2.1:

1. **Sharding (T2.2):**
   - `segments/00/`, `segments/01/`, ... directory sharding
   - Phase 1: flat `segments/` directory

2. **Compaction (T3.2):**
   - Merge small segments into larger ones
   - Phase 1: segments never compacted

3. **Tombstones (T2.2):**
   - `.tombstones` files for deleted records
   - Phase 1: no deletes, immutable segments only

4. **Inverted Index (T4.x):**
   - Global index files + version tracking in manifest
   - Phase 1: no index

5. **Compaction State Tracking (T3.2):**
   - `compaction_in_progress: Option<CompactionState>` field in Manifest
   - Phase 1: omit field entirely

6. **Multi-part Checkpoints:**
   - Split very large manifests across multiple files
   - Phase 1: assume manifests <10 KB

7. **Manifest Compression:**
   - gzip manifests for long-term storage
   - Phase 1: plain JSON

### 7.2 Anti-Patterns to Avoid

1. **Mutable manifests (except tags):**
   - Manifests are IMMUTABLE after commit
   - Only exception: `tag_snapshot()` modifies tags atomically
   - DO NOT allow editing segments/stats/version after commit

2. **Blocking GC:**
   - GC must NOT delete files immediately
   - Use two-phase: collect (move to gc/) → purge (delete from gc/)
   - If collect logic is wrong, files recoverable from gc/

3. **Non-atomic writes:**
   - Always use atomic_write_json (temp file + rename)
   - Never write directly to manifest/current files

4. **Skipping fsync:**
   - Always fsync manifest before updating current pointer
   - Always fsync current.json.tmp before rename
   - Always fsync directory after rename (Linux)

5. **Caching without invalidation:**
   - Phase 1: only cache `current` manifest
   - Do NOT cache old manifests without invalidation strategy

6. **Over-engineering:**
   - Keep it simple: single file, ~600 LOC
   - Don't add features not in this spec
   - Don't optimize prematurely (no HashMap cache, no segment batching)

---

## 8. Test Plan (Complete)

### 8.1 Unit Tests (in `storage_v2/manifest.rs`)

**Serde & Data Structures (6 tests):**
1. `test_manifest_serde_roundtrip` — Serialize → deserialize → identical
2. `test_segment_descriptor_from_meta` — SegmentMeta → SegmentDescriptor conversion
3. `test_manifest_stats_computation` — ManifestStats::from_segments() correctness
4. `test_snapshot_diff_compute` — SnapshotDiff::compute() correctness
5. `test_segment_descriptor_may_contain` — Zone map filtering logic
6. `test_manifest_serde_optional_fields` — tags=empty, parent_version=None

**File I/O Helpers (5 tests):**
7. `test_atomic_write_json_creates_file` — Write → read → identical
8. `test_atomic_write_json_pretty_format` — JSON is pretty-printed
9. `test_read_json_missing_file` — Returns Io error
10. `test_fsync_directory_no_error` — Call on temp dir, no crash
11. `test_parse_segment_id_from_filename` — Filename parsing correctness

**ManifestStore Core (8 tests):**
12. `test_manifest_store_ephemeral` — Create ephemeral, verify no db_path
13. `test_manifest_store_create_new_database` — Create → verify files exist
14. `test_manifest_store_open_existing` — Create → reopen → same version
15. `test_manifest_store_commit_sequential` — v1 → v2 → v3 commits
16. `test_manifest_store_commit_updates_current` — Commit → current() matches
17. `test_manifest_store_commit_monotonicity_check` — Try commit v1 again → error
18. `test_manifest_store_load_manifest` — Load specific version
19. `test_manifest_store_next_segment_id_increments` — Allocate IDs → 1, 2, 3

**Snapshot Operations (6 tests):**
20. `test_find_snapshot_by_tag` — Tag v2 → find → returns 2
21. `test_find_snapshot_not_found` — Search nonexistent tag → None
22. `test_list_snapshots_all` — Create 3 versions → list → 3 entries
23. `test_list_snapshots_filtered_by_tag` — Filter by tag key
24. `test_tag_snapshot_persists` — Tag → reopen → tag still present
25. `test_tag_snapshot_overwrites_existing` — Tag twice → last value wins

**Diff Computation (4 tests):**
26. `test_diff_empty_to_populated` — v1 (0 segs) → v2 (3 segs)
27. `test_diff_same_version` — v1 → v1 diff is empty
28. `test_diff_mixed_changes` — v1 (3 segs) → v2 (2 removed, 3 added)
29. `test_diff_stats_match` — Verify stats_from/stats_to correct

**Garbage Collection (5 tests):**
30. `test_gc_collect_unreferenced` — Retention=3 → old segments in gc/
31. `test_gc_collect_preserves_referenced` — Recent segments untouched
32. `test_gc_collect_handles_gaps` — Missing manifest versions → no crash
33. `test_gc_purge_deletes_files` — Purge → files deleted
34. `test_gc_ephemeral_no_op` — Ephemeral → gc_collect returns empty

### 8.2 Integration Tests (in `tests/integration/manifest_store_tests.rs`)

**End-to-End Workflows (6 tests):**
1. `test_end_to_end_create_commit_reopen` — Full lifecycle
2. `test_crash_simulation_partial_write` — Kill mid-write → DB still opens
3. `test_concurrent_reader_isolation` — Reader + writer concurrency
4. `test_large_manifest_1000_segments` — Scale test
5. `test_gc_with_retention_policy` — GC with 100 versions
6. `test_tag_find_diff_workflow` — Tag → find → diff integration

### 8.3 Test Fixtures & Helpers

```rust
/// Create test segment descriptor for unit tests
fn make_test_segment_descriptor(
    segment_id: u64,
    segment_type: &str, // "nodes" or "edges"
    record_count: u64,
) -> SegmentDescriptor {
    SegmentDescriptor {
        segment_id,
        file_path: format!("segments/seg_{:06}_{}.seg", segment_id, segment_type),
        record_count,
        byte_size: record_count * 100, // fake size
        node_types: if segment_type == "nodes" {
            HashSet::from(["FUNCTION".to_string()])
        } else {
            HashSet::new()
        },
        file_paths: if segment_type == "nodes" {
            HashSet::from(["src/main.rs".to_string()])
        } else {
            HashSet::new()
        },
        edge_types: if segment_type == "edges" {
            HashSet::from(["CALLS".to_string()])
        } else {
            HashSet::new()
        },
    }
}

/// Create test manifest for unit tests
fn make_test_manifest(
    version: u64,
    node_segs: Vec<SegmentDescriptor>,
    edge_segs: Vec<SegmentDescriptor>,
) -> Manifest {
    let stats = ManifestStats::from_segments(&node_segs, &edge_segs);
    Manifest {
        version,
        created_at: 1234567890,
        node_segments: node_segs,
        edge_segments: edge_segs,
        tags: HashMap::new(),
        stats,
        parent_version: if version > 1 { Some(version - 1) } else { None },
    }
}

/// Create temp database directory for tests
fn setup_temp_db() -> (tempfile::TempDir, PathBuf) {
    let temp_dir = tempfile::tempdir().unwrap();
    let db_path = temp_dir.path().to_path_buf();
    (temp_dir, db_path)
}
```

### 8.4 Critical Validation Tests

**Crash Simulation:**
```rust
#[test]
fn test_crash_simulation_partial_write() {
    let (temp_dir, db_path) = setup_temp_db();

    // Create database + commit v1
    let mut store = ManifestStore::create(&db_path).unwrap();
    let manifest = store.create_manifest(vec![], vec![], None).unwrap();
    store.commit(manifest).unwrap();

    // Simulate crash: write manifest v2 but don't update current.json
    let manifest_v2_path = manifest_file_path(&db_path, 2);
    let manifest_v2 = make_test_manifest(2, vec![make_test_segment_descriptor(1, "nodes", 100)], vec![]);
    atomic_write_json(&manifest_v2_path, &manifest_v2).unwrap();
    // DO NOT write current.json (simulates crash)

    // Reopen database → should load v1 (current.json still points to v1)
    let store2 = ManifestStore::open(&db_path).unwrap();
    assert_eq!(store2.current().version, 1);
    assert_eq!(store2.current().node_segments.len(), 0);
}
```

**Concurrent Reader Isolation:**
```rust
#[test]
fn test_concurrent_reader_isolation() {
    let (temp_dir, db_path) = setup_temp_db();

    // Create database + commit v1 with 1 segment
    let mut store = ManifestStore::create(&db_path).unwrap();
    let seg1 = make_test_segment_descriptor(1, "nodes", 100);
    let manifest_v1 = store.create_manifest(vec![seg1.clone()], vec![], None).unwrap();
    store.commit(manifest_v1).unwrap();

    // Spawn reader thread that opens v1
    let db_path_clone = db_path.clone();
    let reader_thread = std::thread::spawn(move || {
        let reader_store = ManifestStore::open(&db_path_clone).unwrap();
        assert_eq!(reader_store.current().version, 1);
        std::thread::sleep(std::time::Duration::from_millis(100)); // simulate slow read
        assert_eq!(reader_store.current().node_segments.len(), 1);
        reader_store.current().node_segments[0].segment_id // return segment ID
    });

    // Main thread commits v2 with different segments
    std::thread::sleep(std::time::Duration::from_millis(50));
    let seg2 = make_test_segment_descriptor(2, "nodes", 200);
    let manifest_v2 = store.create_manifest(vec![seg2.clone()], vec![], None).unwrap();
    store.commit(manifest_v2).unwrap();

    // Reader thread should still see v1 (isolation)
    let reader_segment_id = reader_thread.join().unwrap();
    assert_eq!(reader_segment_id, 1); // not 2

    // New reader sees v2
    let new_store = ManifestStore::open(&db_path).unwrap();
    assert_eq!(new_store.current().version, 2);
    assert_eq!(new_store.current().node_segments[0].segment_id, 2);
}
```

**GC Safety:**
```rust
#[test]
fn test_gc_safety_retention_boundary() {
    let (temp_dir, db_path) = setup_temp_db();
    let mut store = ManifestStore::create(&db_path).unwrap();

    // Create segments dir and write dummy files
    let segments_dir = db_path.join("segments");
    std::fs::create_dir_all(&segments_dir).unwrap();

    // Create v1-v10 manifests, each with 1 unique segment
    for i in 1..=10 {
        let seg_id = store.next_segment_id();
        let seg_path = segments_dir.join(format!("seg_{:06}_nodes.seg", seg_id));
        std::fs::write(&seg_path, b"dummy segment data").unwrap();

        let seg = make_test_segment_descriptor(seg_id, "nodes", 100);
        let manifest = store.create_manifest(vec![seg], vec![], None).unwrap();
        store.commit(manifest).unwrap();
    }

    // GC with retention=3 (keep v8, v9, v10)
    let moved = store.gc_collect(3).unwrap();

    // Verify: segments 1-7 moved to gc/, segments 8-10 untouched
    assert_eq!(moved.len(), 7);
    for i in 1..=7 {
        let gc_path = db_path.join("gc").join(format!("seg_{:06}_nodes.seg", i));
        assert!(gc_path.exists(), "seg {} not in gc/", i);
    }
    for i in 8..=10 {
        let seg_path = segments_dir.join(format!("seg_{:06}_nodes.seg", i));
        assert!(seg_path.exists(), "seg {} incorrectly moved to gc/", i);
    }
}
```

---

## 9. Module Structure & Exports

### 9.1 File Organization

**Phase 1:** Single file `storage_v2/manifest.rs` (~600 LOC).

**Future (if >800 LOC):** Split into:
- `storage_v2/manifest/types.rs` — data structures
- `storage_v2/manifest/store.rs` — ManifestStore implementation
- `storage_v2/manifest/diff.rs` — diff computation
- `storage_v2/manifest/mod.rs` — re-exports

### 9.2 Module Exports

Update `packages/rfdb-server/src/storage_v2/mod.rs`:

```rust
pub mod types;
pub mod string_table;
pub mod bloom;
pub mod zone_map;
pub mod writer;
pub mod segment;
pub mod manifest; // NEW

pub use types::*;
pub use string_table::StringTableV2;
pub use bloom::BloomFilter;
pub use zone_map::ZoneMap;
pub use writer::{NodeSegmentWriter, EdgeSegmentWriter};
pub use segment::{NodeSegmentV2, EdgeSegmentV2};

// NEW: Manifest exports
pub use manifest::{
    Manifest,
    ManifestStore,
    SegmentDescriptor,
    ManifestStats,
    CurrentPointer,
    SnapshotInfo,
    SnapshotDiff,
};
```

### 9.3 Public API Surface

**External callers (e.g., `engine.rs`) should use:**
- `ManifestStore::open(path)` / `create(path)` / `ephemeral()`
- `store.current()` — get current manifest
- `store.create_manifest(...)` — prepare new manifest
- `store.commit(manifest)` — atomically commit
- `store.next_segment_id()` — allocate segment ID
- `store.find_snapshot(tag_key, tag_value)` — find by tag
- `store.list_snapshots(filter)` — list all snapshots
- `store.diff_snapshots(from, to)` — compute diff
- `store.gc_collect(retention)` / `gc_purge()` — garbage collection

**Internal helpers (not exported):**
- `atomic_write_json()`, `read_json()`, `fsync_directory()`
- `manifest_file_path()`, `parse_segment_id_from_filename()`
- `current_timestamp()`

---

## 10. Dependencies (No New Crates)

Already in `Cargo.toml`:
```toml
[dependencies]
serde = { version = "1", features = ["derive"] }
serde_json = "1"
blake3 = "1"
```

No new dependencies required for Phase 1.

---

## 11. Error Handling

### 11.1 Existing Error Types (Use As-Is)

From `error.rs`:
- `GraphError::Io(std::io::Error)` — file operations
- `GraphError::Json(serde_json::Error)` — manifest serialization
- `GraphError::InvalidFormat(String)` — corrupt manifests, validation failures

**No new error variants needed for Phase 1.**

### 11.2 Error Contexts

Add context strings for better debugging:

```rust
// Example: manifest load failure
Err(GraphError::InvalidFormat(format!(
    "Manifest version mismatch: expected {}, got {}",
    version, manifest.version
)))

// Example: commit monotonicity violation
Err(GraphError::InvalidFormat(format!(
    "Cannot commit version {} (current: {})",
    manifest.version, self.current.version
)))
```

### 11.3 Error Propagation

Use `?` operator for clean error propagation:

```rust
pub fn commit(&mut self, manifest: Manifest) -> Result<()> {
    let manifest_path = manifest_file_path(db_path, manifest.version);
    atomic_write_json(&manifest_path, &manifest)?; // auto-converts Io/Json errors
    Ok(())
}
```

---

## 12. Platform Considerations

### 12.1 Atomic Rename

**POSIX (Linux, macOS):** `std::fs::rename()` is atomic if src and dst are on same filesystem.

**Windows:** `std::fs::rename()` is NOT atomic if target exists. Must use `ReplaceFile` API or `fs2` crate.

**Phase 1 strategy:**
- Use `std::fs::rename()` (works on POSIX)
- Add TODO comment for Windows atomic replace (defer to T2.2)

**Future (T2.2):**
```rust
#[cfg(windows)]
fn atomic_rename(src: &Path, dst: &Path) -> Result<()> {
    use std::os::windows::fs::rename;
    rename(src, dst)?;
    Ok(())
}
```

### 12.2 Directory Fsync

**Linux (ext4/XFS):** Required for durability. Must fsync parent directory after rename.

**macOS (HFS+/APFS):** Not required (filesystem auto-persists directory metadata).

**Windows (NTFS):** Not required (filesystem auto-persists).

**Implementation:** Conditional compilation (see Section 3.3).

### 12.3 File Path Handling

Use `PathBuf` and `Path` (platform-agnostic).

**Avoid:**
- Hardcoded `/` (use `Path::join()`)
- String manipulation of paths (use `Path` methods)

**Correct:**
```rust
let manifest_path = db_path.join("manifests").join(format!("{:06}.json", version));
```

---

## 13. Alignment with Project Vision

### 13.1 "AI Should Query the Graph, Not Read Code"

**Manifest zone maps enable query planning without opening segments:**

Example: "Find FUNCTION nodes in `src/main.rs`"

```rust
// Query planner checks manifest zone maps
let relevant_segments: Vec<&SegmentDescriptor> = manifest.node_segments.iter()
    .filter(|seg| seg.may_contain(Some("FUNCTION"), Some("src/main.rs"), None))
    .collect();

// Open ONLY relevant segments (not all segments)
for seg in relevant_segments {
    let segment = NodeSegmentV2::open(&seg.file_path)?;
    // ... scan segment
}
```

This is Iceberg's pattern: metadata-driven pruning. Grafema's core value proposition.

### 13.2 Time-Travel Queries

Snapshot chain enables:
- "What did the graph look like at commit abc123?" → find by tag → load manifest
- "What changed between analysis runs?" → diff_snapshots()
- "Rollback to previous snapshot" → load old manifest → regenerate current

### 13.3 Incremental Analysis

Diff-based incremental updates (T3.x):
```rust
let diff = store.diff_snapshots(last_analysis_version, current_version)?;
// Only re-analyze files in diff.added_node_segments
// Skip unchanged segments (cached results)
```

### 13.4 No Shortcuts

Don's Root Cause Policy applies:
- Atomic write protocol must be correct (fsync + directory fsync)
- GC safety must be airtight (two-phase collect/purge)
- Crash recovery must work (partial writes leave DB consistent)

If tests fail → fix root cause, don't workaround.

---

## 14. Success Criteria

### 14.1 Functional Requirements

- [ ] Can create new database with first manifest (v1)
- [ ] Can commit sequential manifests (v1 → v2 → v3)
- [ ] Can reopen database and load current manifest
- [ ] Can tag snapshots and find by tag
- [ ] Can list all snapshots (with optional tag filter)
- [ ] Can compute diff between two snapshots
- [ ] Can collect unreferenced segments (move to gc/)
- [ ] Can purge gc/ directory
- [ ] Atomic commit works (crash mid-write → DB still opens)
- [ ] Concurrent readers isolated (reader sees old snapshot during writer commit)

### 14.2 Test Coverage

- [ ] All 34 unit tests pass
- [ ] All 6 integration tests pass
- [ ] Crash simulation test passes (kill mid-write)
- [ ] Concurrent reader test passes (isolation verified)
- [ ] GC safety test passes (retention boundary correct)

### 14.3 Code Quality

- [ ] No clippy warnings (run `cargo clippy --all-targets`)
- [ ] No panics in production code (except debug_assert)
- [ ] All public APIs documented with `///` comments
- [ ] All error paths tested (missing files, corrupt JSON, etc.)
- [ ] No TODO/FIXME/HACK comments (except planned future work)

### 14.4 Performance

- [ ] Commit latency <10ms for 100-segment manifest (informal test, not hard requirement)
- [ ] GC collect <1s for 1000 manifests (informal test)
- [ ] No O(N²) algorithms (verify with Big-O analysis)

---

## 15. Next Steps After Phase 1

### T2.2 — Sharding + Tombstones
- Directory sharding: `segments/00/`, `segments/01/`, ...
- Tombstone files for deleted records
- Manifest tracks tombstone versions

### T3.1 — Batch Commits
- Multi-threaded segment writes
- Parallel segment generation
- Atomic batch commit (all segments + manifest in one transaction)

### T3.2 — Compaction
- Merge small segments into larger ones
- Compaction state tracking in manifest
- Background compaction workers

### T4.x — Inverted Index
- Global inverted index files
- Manifest tracks index version
- Query planner uses index + zone maps

---

## 16. Risks & Mitigations

### 16.1 Risk: Windows Atomic Rename

**Problem:** `std::fs::rename()` not atomic on Windows if target exists.

**Mitigation:**
- Phase 1: Document limitation (current.json must not exist during rename)
- Phase 1: Works on POSIX (Linux, macOS) — acceptable for now
- T2.2: Add Windows-specific atomic replace via `fs2` crate or `ReplaceFile` API

### 16.2 Risk: Large Manifest Performance

**Problem:** 10,000-segment manifest → 300KB JSON → slow to parse.

**Mitigation:**
- Phase 1: Assume <1000 segments (typical)
- T3.2: If manifests grow large → add multi-part checkpoints (Iceberg pattern)
- T3.2: If serialization slow → switch to bincode or protobuf (breaking change)

### 16.3 Risk: GC Deletes Referenced Segments

**Problem:** Bug in gc_collect logic → deletes segments still referenced.

**Mitigation:**
- Two-phase GC (collect → purge) prevents permanent loss
- Integration test verifies retention boundary
- If bug found → move files back from gc/, fix logic, retry

### 16.4 Risk: Concurrent Writers Corrupt Manifest

**Problem:** Two writers commit same version → manifest file overwritten.

**Mitigation:**
- Phase 1: Single-threaded only (no concurrent writes)
- T3.1: Add optimistic concurrency control (check version before commit)
- T3.1: Add file locking or coordinator process

### 16.5 Risk: Fsync Performance on HDD

**Problem:** Fsync on spinning rust (HDD) → 10-50ms latency per call.

**Mitigation:**
- Phase 1: Assume SSD (modern dev/prod environments)
- T3.1: Add async commit option (fsync in background, best-effort durability)
- T3.1: Add batch commits (multiple manifests, single fsync)

---

## 17. Summary for Rob Pike (Implementation)

**You will receive this spec and implement Phase 1-6 in order.**

**Key points:**
- Follow the struct definitions exactly (serde attributes matter)
- Implement phases sequentially (don't skip ahead)
- Write tests BEFORE implementation (TDD)
- Use `?` operator for error propagation (clean code)
- Add `#[cfg(debug_assertions)]` for expensive validation
- Keep functions short (<50 lines)
- Match existing code style (check `storage_v2/writer.rs` for patterns)

**Critical invariants to maintain:**
- Manifests immutable after commit (except tags)
- Version numbers strictly increasing (gaps OK, duplicates forbidden)
- Stats must match segment descriptors (validated in debug builds)
- Atomic write: temp file + fsync + rename + fsync directory
- GC: two-phase (collect → purge), never delete directly

**When stuck:**
- Read Don's plan again (architectural context)
- Check existing code (`storage_v2/types.rs`, `writer.rs`)
- Ask questions BEFORE writing code (no blind guessing)

**Success = all 40 tests pass + clippy clean + manual smoke test.**

---

## Appendix A: Storage Layout Example

```
example.rfdb/
├── current.json                      # {"version": 5}
├── manifests/
│   ├── 000001.json                   # Manifest v1 (immutable)
│   ├── 000002.json                   # Manifest v2
│   ├── 000003.json                   # Manifest v3
│   ├── 000004.json                   # Manifest v4 (gap: crashed)
│   └── 000005.json                   # Manifest v5 (current)
├── segments/
│   ├── seg_000001_nodes.seg          # Node segment 1 (v1)
│   ├── seg_000001_edges.seg          # Edge segment 1 (v1)
│   ├── seg_000002_nodes.seg          # Node segment 2 (v2)
│   ├── seg_000003_nodes.seg          # Node segment 3 (v3)
│   └── seg_000004_edges.seg          # Edge segment 4 (v5)
└── gc/                               # Unreferenced segments (pending deletion)
    ├── seg_000001_nodes.seg          # Moved by gc_collect
    └── seg_000001_edges.seg
```

**Manifest v5 content (example):**
```json
{
  "version": 5,
  "created_at": 1707826800,
  "node_segments": [
    {
      "segment_id": 2,
      "file_path": "segments/seg_000002_nodes.seg",
      "record_count": 1500,
      "byte_size": 245000,
      "node_types": ["FUNCTION", "CLASS"],
      "file_paths": ["src/main.rs", "src/lib.rs"]
    },
    {
      "segment_id": 3,
      "file_path": "segments/seg_000003_nodes.seg",
      "record_count": 800,
      "byte_size": 130000,
      "node_types": ["FUNCTION"],
      "file_paths": ["src/utils.rs"]
    }
  ],
  "edge_segments": [
    {
      "segment_id": 4,
      "file_path": "segments/seg_000004_edges.seg",
      "record_count": 2300,
      "byte_size": 180000,
      "edge_types": ["CALLS", "IMPORTS_FROM"]
    }
  ],
  "tags": {
    "commit_sha": "abc123",
    "analysis_run": "success"
  },
  "stats": {
    "total_nodes": 2300,
    "total_edges": 2300,
    "node_segment_count": 2,
    "edge_segment_count": 1
  },
  "parent_version": 3
}
```

**Current pointer (`current.json`):**
```json
{
  "version": 5
}
```

---

## Appendix B: Commit Protocol Diagram

```
Commit Flow (v1 → v2):

1. Prepare
   └─ create_manifest() → Manifest v2 (in memory)

2. Write Manifest
   ├─ Write manifests/000002.json.tmp
   ├─ Fsync manifests/000002.json.tmp
   └─ Rename .tmp → manifests/000002.json

3. Update Current Pointer (ATOMIC)
   ├─ Write current.json.tmp ({"version": 2})
   ├─ Fsync current.json.tmp
   ├─ Rename current.json.tmp → current.json
   └─ Fsync directory (Linux only)

4. Update Cache
   └─ self.current = manifest_v2

Result: Either old version active (crash before step 3) or new version active.
Never torn read.
```

---

## Appendix C: GC Algorithm Diagram

```
GC Flow (retention=3):

Current version: 10
Retention window: [7, 8, 9, 10]

1. Collect Referenced Segments
   ├─ Load manifest v7 → segments {10, 11}
   ├─ Load manifest v8 → segments {10, 11, 12}
   ├─ Load manifest v9 → segments {11, 12, 13}
   └─ Load manifest v10 → segments {12, 13, 14}
   Referenced: {10, 11, 12, 13, 14}

2. Scan segments/ Directory
   Files: seg_000010_nodes.seg, seg_000011_nodes.seg, ..., seg_000009_nodes.seg
   Unreferenced: {1, 2, 3, 4, 5, 6, 7, 8, 9}

3. Move to gc/
   ├─ mv segments/seg_000001_nodes.seg → gc/seg_000001_nodes.seg
   ├─ mv segments/seg_000002_nodes.seg → gc/seg_000002_nodes.seg
   └─ ...

4. Purge (separate call)
   ├─ rm gc/seg_000001_nodes.seg
   ├─ rm gc/seg_000002_nodes.seg
   └─ ...

Safety: If step 1-2 logic wrong → files in gc/, not deleted.
```

---

**End of Specification**

This document is complete and ready for implementation. Rob Pike should follow phases sequentially. Kent Beck should write tests first (TDD). Kevlin Henney will review code quality after each phase.
