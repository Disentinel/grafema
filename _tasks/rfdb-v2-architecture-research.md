# RFDB v2 Architecture Research

> –î–∞—Ç–∞: 2026-02-10
> –£—á–∞—Å—Ç–Ω–∏–∫–∏: –í–∞–¥–∏–º, Claude
> Linear issues: REG-404 (flush performance), REG-405 (memory 20GB)

---

## 1. –ü—Ä–æ–±–ª–µ–º–∞: —Ç–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ RFDB –Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è

### –ò–∑–º–µ—Ä–µ–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ (2500 —Ñ–∞–π–ª–æ–≤)

- 1.3M nodes, 9.3M edges
- **20 GB RAM** –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
- Flush: 5 –º–∏–Ω—É—Ç (–∏–∑-–∑–∞ swap thrashing)
- –ù–∞ –¥–∏—Å–∫–µ: nodes.bin ~117 MB, edges.bin ~495 MB

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–∞–º—è—Ç–∏ (—Ç–µ–∫—É—â–∞—è)

```
GraphEngine {
    // ‚úÖ –ù–∞ –¥–∏—Å–∫–µ (mmap) ‚Äî –û–ö
    nodes_segment: mmap(nodes.bin)
    edges_segment: mmap(edges.bin)

    // ‚ö†Ô∏è –í—Ä–µ–º–µ–Ω–Ω—ã–µ ‚Äî "–æ—á–∏—â–∞—é—Ç—Å—è" –ø—Ä–∏ flush (–Ω–æ capacity —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è!)
    delta_log: Vec<Delta>                    // O(ops) ‚Äî –î–£–ë–õ–¨ delta_nodes/edges
    delta_nodes: HashMap<u128, NodeRecord>   // O(new_nodes)
    delta_edges: Vec<EdgeRecord>             // O(new_edges)

    // üî¥ –í–°–ï–ì–î–ê –í RAM, –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è —Å –ü–û–õ–ù–´–ú –≥—Ä–∞—Ñ–æ–º
    adjacency: HashMap<u128, Vec<usize>>         // O(total_edges)
    reverse_adjacency: HashMap<u128, Vec<usize>> // O(total_edges)
    index_set.id_index: HashMap<u128, usize>     // O(total_nodes)
    index_set.type_index: HashMap<String, Vec<usize>>  // O(total_nodes)
    index_set.file_index: HashMap<String, Vec<usize>>  // O(total_nodes)
}
```

### 4 –∫–æ—Ä–Ω–µ–≤—ã–µ –ø—Ä–∏—á–∏–Ω—ã –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è 20 GB

**1. –î–≤–æ–π–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ: delta_log –¥—É–±–ª–∏—Ä—É–µ—Ç delta_nodes/delta_edges**

```rust
// engine.rs:698-699 ‚Äî –∫–∞–∂–¥—ã–π node –∫–ª–æ–Ω–∏—Ä—É–µ—Ç—Å—è –î–í–ê–ñ–î–´
fn add_nodes(&mut self, nodes: Vec<NodeRecord>) {
    for node in nodes {
        self.delta_log.push(Delta::AddNode(node.clone()));  // CLONE #1
        self.apply_delta(&Delta::AddNode(node));             // inside: node.clone() ‚Üí CLONE #2
    }
}
```

delta_log –Ω–∏–≥–¥–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —á—Ç–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –ø—Ä–∏ flush, –Ω–æ delta_nodes/delta_edges —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ.

**2. Metadata strings –æ–≥—Ä–æ–º–Ω—ã–µ –∏ –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ**

–°—Ä–µ–¥–Ω–∏–π metadata per node: ~300-400 bytes JSON:
```json
{"originalId":"FUNCTION->handleAuth->AuthController->module->src/controllers/auth/AuthController.ts",
 "line":45,"column":2,"async":true,"generator":false,"arrowFunction":false,
 "isMethod":true,"isClassMethod":true,"params":["req","res","next"]}
```

–°—Ä–µ–¥–Ω–∏–π metadata per edge: ~250-300 bytes (–î–í–ê originalId):
```json
{"_origSrc":"FUNCTION->handleAuth->...","_origDst":"FUNCTION->processOrder->...",
 "argIndex":0}
```

`originalId` –¥—É–±–ª–∏—Ä—É–µ—Ç info –∏–∑ id/name/file. `_origSrc/_origDst` –¥—É–±–ª–∏—Ä—É—é—Ç src/dst.
~30-40% metadata ‚Äî –º—É—Å–æ—Ä.

**3. Vec::clear() –Ω–µ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –ø–∞–º—è—Ç—å**

```rust
self.delta_log.clear();      // len=0, capacity=10.6M ‚Üí ~5 GB retained
self.delta_nodes.clear();    // entries=0, table=2M buckets ‚Üí ~1 GB retained
self.delta_edges.clear();    // len=0, capacity=9.3M ‚Üí ~4.5 GB retained
```

Rust `Vec::clear()` –∑–∞–Ω—É–ª—è–µ—Ç length, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç allocated capacity. –ù—É–∂–Ω–æ `= Vec::new()`.

**4. Flush = –ø–æ–ª–Ω–∞—è –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ RAM (Catch-22)**

```rust
let mut all_nodes = Vec::new();  // Clone #3: –í–°–ï segment + delta ‚Üí heap
let mut all_edges = Vec::new();  // Clone #3: –í–°–ï segment + delta ‚Üí heap
```

–ù–µ–ª—å–∑—è flush –ø—Ä–∏ –Ω–µ—Ö–≤–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏ ‚Äî flush —Å–∞–º —Ç—Ä–µ–±—É–µ—Ç O(–ø–æ–ª–Ω—ã–π_–≥—Ä–∞—Ñ) RAM.

### –†–∞—Å—á—ë—Ç –ø–∞–º—è—Ç–∏ (1.3M nodes, 9.3M edges)

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | Per-record | Records | √ócopies | –ò—Ç–æ–≥–æ |
|-----------|-----------|---------|---------|-------|
| Nodes (delta_log + delta_nodes) | ~680B | 1.3M | √ó2 | **1.77 GB** |
| Edges (delta_log + delta_edges) | ~470B | 9.3M | √ó2 | **8.74 GB** |
| adjacency + reverse_adj | ~24B/edge | 9.3M | √ó1 | **0.45 GB** |
| HashMap overhead + fragmentation | | | | **~0.5 GB** |
| **Pre-flush** | | | | **~11.5 GB** |

–ü–∏–∫ –ø—Ä–∏ flush (+all_nodes +all_edges +StringTable): **~17 GB**
–° –∞–ª–ª–æ–∫–∞—Ç–æ—Ä–æ–º (fragmentation ~15-20%): **~20 GB**

### Post-flush: indexes –º–∞—Å—à—Ç–∞–±–∏—Ä—É—é—Ç—Å—è —Å –ü–û–õ–ù–´–ú –≥—Ä–∞—Ñ–æ–º

| Scale | Nodes | Edges | Post-flush RAM |
|-------|-------|-------|----------------|
| 2.5K —Ñ–∞–π–ª–æ–≤ | 1.3M | 9.3M | ~500 MB (+ retained capacity) |
| 100K —Ñ–∞–π–ª–æ–≤ | ~50M | ~350M | ~20 GB |
| 1B —Ñ–∞–π–ª–æ–≤ | ~5B | ~35B | ~2 TB |

### Flush pipeline (—Ç–µ–∫—É—â–∏–π, –æ–¥–Ω–æ–ø–æ—Ç–æ—á–Ω—ã–π)

| –≠—Ç–∞–ø | –ß—Ç–æ –¥–µ–ª–∞–µ—Ç | –î–∞–Ω–Ω—ã–µ | –í—Ä–µ–º—è (SSD) |
|------|-----------|--------|-------------|
| 1. Collect nodes | Clone segment+delta | ~260 MB alloc | CPU |
| 2. Collect edges | Clone segment+delta | ~1.4 GB alloc | CPU |
| 3. Build StringTable | 9.3M HashMap lookups √ó2 | CPU-bound | ~5-10 sec |
| 4. Write nodes.bin | 117 MB BufWriter | I/O | 0.06 sec |
| 5. Write edges.bin | 495 MB BufWriter | I/O | 0.25 sec |
| 6. Rebuild adjacency | 9.3M HashMap::insert | ~150 MB | CPU |
| 7. Rebuild reverse_adj | 9.3M HashMap::insert | ~150 MB | CPU |
| 8. Rebuild index_set | Scan all nodes | CPU+mmap | CPU |

rayon –µ—Å—Ç—å –≤ Cargo.toml, –Ω–æ –Ω–∏–≥–¥–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è.

---

## 2. –§–∞–∑—ã –∂–∏–∑–Ω–∏ –≥—Ä–∞—Ñ–∞ Grafema

| –§–∞–∑–∞ | –ü–∞—Ç—Ç–µ—Ä–Ω | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|-------|---------|-----------|
| **1. Analysis** (—Ñ–∞–π–ª ‚Üí –Ω–æ–¥—ã/—ç–¥–∂–∏) | Heavy write, batch, per-file | Write throughput |
| **2. Enrichment** (–∫—Ä–æ—Å—Å-—Ñ–∞–π–ª–æ–≤—ã–µ —Å–≤—è–∑–∏) | Read many + write few, random access | Read by type/file + write |
| **3. Query** (MCP/CLI/GUI) | Read-only, random traversal | Read latency, adjacency |
| **4. Re-analysis** (–∏–∑–º–µ–Ω–∏–ª—Å—è 1 —Ñ–∞–π–ª) | Delete old + write new, per-file | Incremental update |

–¢–µ–∫—É—â–∏–π RFDB –æ–±—Å–ª—É–∂–∏–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–∑—ã –æ–¥–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π ‚Äî –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–±–ª–µ–º—ã.

---

## 3. –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ RFDB v2

1. **Immediate queryability** ‚Äî –Ω–æ–¥—ã/—ç–¥–∂–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ insert, –±–µ–∑ flush
2. **O(1) RAM** ‚Äî RAM –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –≥—Ä–∞—Ñ–∞, —Ä–∞—Å—Ç—ë—Ç —Ç–æ–ª—å–∫–æ –¥–∏—Å–∫
3. **Incremental updates** ‚Äî —É–¥–∞–ª–∏—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –≤—Å–µ–≥–æ
4. **Fast adjacency** ‚Äî `neighbors(nodeId)` –∏ `reverse_neighbors(nodeId)` –∑–∞ O(k)
5. **Type/file queries** ‚Äî –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ –Ω–æ–¥—ã —Ç–∏–ø–∞ X –∏–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞ Y –∑–∞ O(k)
6. **Attr search** ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ–∏—á–∞, –ø–æ–∏—Å–∫ –ø–æ metadata –ø–æ–ª—è–º (object, method, etc.)

---

## 4. –ú–∏—Ä–æ–≤–æ–π –æ–ø—ã—Ç: edge ownership –∏ incremental updates

### –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã (closest prior art)

| –°–∏—Å—Ç–µ–º–∞ | –ü–æ–¥—Ö–æ–¥ –∫ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ—Å—Ç–∏ |
|---------|--------------------------|
| **Sourcetrail** | SQLite, `DELETE FROM edges WHERE source_file_id = X`. Edges owned by —Ñ–∞–π–ª —Å call site. |
| **CodeQL** | TRAP file per source ‚Üí full rebuild (no real incremental). Research: iQL (2023) ‚Äî diff relational tuples. |
| **Joern** | OverflowDB ‚Üí flatgraph. Hash-based invalidation. In-memory, not O(1) RAM. |

### Graph databases

| –°–∏—Å—Ç–µ–º–∞ | –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ | –ü—Ä–∏–º–µ–Ω–∏–º–æ—Å—Ç—å |
|---------|------------|-------------|
| **Neo4j** | Fixed-size records, doubly-linked edge lists. –ù–µ—Ç source partitioning. | –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç |
| **NebulaGraph** | RocksDB, key = `[src][edge_type][dst]`. Edges stored √ó2 (forward+reverse). | –ö–ª—é—á–µ–≤–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω |
| **TerminusDB** | Immutable layers, succinct data structures, 13.57 bytes/triple. | –ò–¥–µ—è layers |
| **DGraph** | Badger (LSM), RDF triples. –ù–µ—Ç source partitioning. | –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç |

### Social graph systems

| –°–∏—Å—Ç–µ–º–∞ | –ö–ª—é—á–µ–≤–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω |
|---------|-----------------|
| **Facebook TAO** | Edge —Ö—Ä–∞–Ω–∏—Ç—Å—è –Ω–∞ —à–∞—Ä–¥–µ source node. Inverse edges ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏. |
| **LinkedIn LIquid** | Hash-based indexes (2-3 L3 cache misses). Fully in-memory. |

### Research

| –°–∏—Å—Ç–µ–º–∞ | –ö–ª—é—á–µ–≤–∞—è –∏–¥–µ—è |
|---------|--------------|
| **STINGER** | Blocked typed edge lists ‚Äî edges grouped by type in contiguous memory |
| **LiveGraph** (VLDB 2020) | Transactional Edge Log –≤ mmap, sequential adjacency scans |
| **BACH** (VLDB 2025) | LSM-tree: upper levels = adjacency list (write-friendly), lower levels = CSR (read-friendly) |
| **RDF Named Graphs** | `DROP GRAPH file:X` ‚Äî —É–¥–∞–ª—è–µ—Ç –≤—Å–µ —Ç—Ä–∏–ø–ª—ã –≥—Ä–∞—Ñ–∞. –ü—Ä—è–º–æ–π –∞–Ω–∞–ª–æ–≥ –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏. |

### –ï–¥–∏–Ω–æ–≥–ª–∞—Å–Ω—ã–π –æ—Ç–≤–µ—Ç: **source-tagged edges**

–í—Å–µ —Å–∏—Å—Ç–µ–º—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç: –∫–∞–∂–¥—ã–π edge –Ω–µ—Å—ë—Ç `owner_file_id`. Re-analysis = `delete all where owner = file_X` + insert new.

–ö—Ä–æ—Å—Å-—Ñ–∞–π–ª–æ–≤—ã–µ edges: owner = —Ñ–∞–π–ª, —Å–æ–∑–¥–∞–≤—à–∏–π edge (—Ñ–∞–π–ª —Å call site, import statement).
–°—Ç–∞–±–∏–ª—å–Ω—ã–µ ID (BLAKE3 deterministic) —Ä–µ—à–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—É dangling references.

---

## 5. Columnar format

### –ü–æ—á–µ–º—É columnar ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä

–ó–∞–ø—Ä–æ—Å—ã RFDB ‚Äî —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: "–Ω–∞–π–¥–∏ –≤—Å–µ –Ω–æ–¥—ã —Ç–∏–ø–∞ FUNCTION –≤ —Ñ–∞–π–ª–µ X".
–°–∫–∞–Ω–∏—Ä—É–µ—Ç 1-2 –∫–æ–ª–æ–Ω–∫–∏ (4 bytes/node), –Ω–µ —Ç—è–Ω–µ—Ç –ø–æ–ª–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (200+ bytes/node).

Query pattern –∏–∑ `find_by_attr()`:
1. IndexSet –¥–∞—ë—Ç candidate set K (O(1))
2. Scan candidates –ø–æ –∫–∞–∂–¥–æ–π –∫–æ–ª–æ–Ω–∫–µ (O(K))
3. Return IDs

Columnar + IndexSet = –∏–¥–µ–∞–ª—å–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è. Row-oriented –Ω–µ –¥–∞—ë—Ç –≤—ã–∏–≥—Ä—ã—à–∞.

### String table

–û—Ç–¥–µ–ª—å–Ω–∞—è –≥–ª–æ–±–∞–ª—å–Ω–∞—è string table = random access –∑–∞ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–æ–π = —É–±–∏–π—Å—Ç–≤–æ attr search.
**Strings –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω—ã –≤ segment** (per-segment string table, –∫–∞–∫ —Å–µ–π—á–∞—Å).

---

## 6. Apache Iceberg ‚Äî –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ –≤–¥–æ—Ö–Ω–æ–≤–µ–Ω–∏–µ

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Iceberg

```
Catalog (atomic pointer to current metadata.json)
  ‚îî‚îÄ‚îÄ metadata.json (schema, partition spec, snapshot history)
        ‚îî‚îÄ‚îÄ Snapshot N (manifest-list-N.avro)
              ‚îú‚îÄ‚îÄ Manifest 1 (data files + stats: min/max per column, row count)
              ‚îÇ     ‚îú‚îÄ‚îÄ data-file-001.parquet  (IMMUTABLE)
              ‚îÇ     ‚îî‚îÄ‚îÄ data-file-002.parquet
              ‚îî‚îÄ‚îÄ Delete manifest
                    ‚îú‚îÄ‚îÄ delete-file-001 (position deletes)
                    ‚îî‚îÄ‚îÄ delete-file-002 (equality deletes)
```

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã Iceberg

1. **Data files –∏–º–º—É—Ç–∞–±–µ–ª—å–Ω—ã** ‚Äî –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è
2. **Manifest –∑–Ω–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏** ‚Äî query planner –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã
3. **Write = create new files + new manifest + atomic pointer swap**
4. **Delete = –æ—Ç–¥–µ–ª—å–Ω—ã–π delete file**, –Ω–µ tombstone –≤ data file
5. **Compaction = background rewrite** ‚Äî merge, apply deletes. Readers –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è.

### Mapping Iceberg ‚Üí RFDB v2

| Iceberg | RFDB v2 |
|---------|---------|
| Data file (Parquet) | Segment (nodes/edges columnar) |
| Partition by date/region | **Partition by owner_file** |
| Manifest (file stats) | Segment registry (stats per segment) |
| Manifest list (snapshot) | Graph snapshot |
| Position delete file | Deletion bitmap per segment |
| Equality delete | `DELETE WHERE owner_file = X` |
| Compaction | Background segment merge |
| Catalog atomic swap | `current.json` ‚Üí atomic rename |

### –ß—Ç–æ –±–µ—Ä—ë–º –∏–∑ Iceberg

1. **Immutable segments** ‚Äî –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å, —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–æ–≤—ã–µ
2. **Manifest —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏** ‚Äî –∑–Ω–∞–µ–º —á—Ç–æ –≤ –∫–∞–∂–¥–æ–º segment –±–µ–∑ –µ–≥–æ —á—Ç–µ–Ω–∏—è
3. **Snapshot isolation** ‚Äî atomic swap, readers –Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç—Å—è
4. **Partition by owner** ‚Äî delete = drop partition
5. **Background compaction** ‚Äî merge –º–µ–ª–∫–∏—Ö —Ñ–∞–π–ª–æ–≤

### –ß—Ç–æ –æ—Ç–ª–∏—á–∞–µ—Ç –Ω–∞—Å –æ—Ç Iceberg

| Iceberg (analytics) | RFDB (graph) |
|---------------------|--------------|
| Sequential scan –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤ —Å—Ç—Ä–æ–∫ | **Point queries** (get node by ID) |
| –ù–µ—Ç adjacency | **Adjacency ‚Äî –∫–ª—é—á–µ–≤–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è** |
| Partition pruning –ø–æ range | Partition pruning –ø–æ **type + file** |
| Row groups ~128MB | Segments ~100KB-1MB per file |
| S3 (no mmap, high latency) | **Local FS (mmap, low latency)** |

### –ß—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å–≤–µ—Ä—Ö Iceberg

1. **Adjacency layer** ‚Äî sorted mmap files –¥–ª—è forward/reverse neighbor queries
2. **Point query index** ‚Äî node ID ‚Üí (segment, offset), bloom filter per segment
3. **Columnar —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º StringTable** ‚Äî –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–¥ graph nodes

---

## 7. LSM-tree: write-optimized ‚Üî read-optimized

### –ò–¥–µ—è

–ù–µ –∫–æ–ø–∏—Ä—É–µ–º Iceberg, –∞ –±–µ—Ä—ë–º –∫–ª—é—á–µ–≤–æ–π –ø—Ä–∏–Ω—Ü–∏–ø LSM-tree: **–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π —Å–ø–µ–∫—Ç—Ä** –º–µ–∂–¥—É write-heavy –∏ read-heavy —Ä–µ–∂–∏–º–∞–º–∏. –ë–∞–∑–∞ —Å–∞–º–∞ —Ä–µ—à–∞–µ—Ç –∫–æ–≥–¥–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å.

### –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç LSM-tree

```
Write path:
  1. Insert ‚Üí MemTable (in-memory sorted structure, –Ω–∞–ø—Ä. skiplist)
  2. MemTable –ø–æ–ª–Ω—ã–π ‚Üí flush –Ω–∞ –¥–∏—Å–∫ –∫–∞–∫ SSTable (Sorted String Table) ‚Üí Level 0
  3. Level 0 –Ω–∞–∫–æ–ø–∏–ª—Å—è ‚Üí compact (merge-sort) ‚Üí Level 1
  4. Level 1 –Ω–∞–∫–æ–ø–∏–ª—Å—è ‚Üí compact ‚Üí Level 2
  ...

Read path:
  1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å MemTable (RAM) ‚Äî O(log n)
  2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Level 0 SSTables ‚Äî –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ, overlapping
  3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Level 1, 2, ... ‚Äî –∫–∞–∂–¥—ã–π —É—Ä–æ–≤–µ–Ω—å sorted, binary search
  4. Bloom filter per SSTable ‚Äî skip –µ—Å–ª–∏ —Ç–æ—á–Ω–æ –Ω–µ—Ç –Ω—É–∂–Ω–æ–≥–æ –∫–ª—é—á–∞
```

**Write –±—ã—Å—Ç—Ä—ã–π:** –≤—Å—ë sequential ‚Äî append –≤ –ª–æ–≥, flush = sequential write. –ù–µ—Ç random I/O.

**Read –º–µ–¥–ª–µ–Ω–Ω–µ–µ:** worst case = –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —É—Ä–æ–≤–Ω–∏. Bloom filters + sorted levels —Å–Ω–∏–∂–∞—é—Ç –¥–æ 1-2 disk reads –æ–±—ã—á–Ω–æ.

**Compaction** ‚Äî –ø–µ—Ä–µ—Ö–æ–¥ write-optimized ‚Üí read-optimized:
- –ë–µ–∑ compaction: –º–Ω–æ–≥–æ –º–µ–ª–∫–∏—Ö —Ñ–∞–π–ª–æ–≤, read –¥–æ—Ä–æ–≥–æ–π
- –ü–æ—Å–ª–µ compaction: –º–µ–Ω—å—à–µ –∫—Ä—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, read –±—ã—Å—Ç—Ä—ã–π
- –í —Ñ–æ–Ω–µ, –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –Ω–∏ reads –Ω–∏ writes

### Mapping LSM ‚Üí RFDB v2

| LSM –∫–æ–Ω—Ü–µ–ø—Ç | RFDB v2 |
|-------------|---------|
| MemTable | Write buffer (—Ç–µ–∫—É—â–∏–π batch –Ω–æ–¥/—ç–¥–∂–µ–π) |
| SSTable Level 0 | –°–≤–µ–∂–∏–µ per-shard —Å–µ–≥–º–µ–Ω—Ç—ã (unsorted, fast write) |
| SSTable Level 1+ | Merged shard —Å–µ–≥–º–µ–Ω—Ç—ã (sorted columnar, fast read) |
| Compaction | Shard merge: –º–µ–ª–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã ‚Üí –∫—Ä—É–ø–Ω—ã–π sorted —Å–µ–≥–º–µ–Ω—Ç |
| Bloom filter | Per-segment node ID filter |

### Resource-adaptive batching

–û–∫–Ω–æ –±–∞—Ç—á–∏–Ω–≥–∞ –∑–∞–≤—è–∑–∞–Ω–æ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:

```
ResourceManager:
  available_ram = system_ram - used_ram

  if available_ram > 4 GB:
    write_buffer_size = 1 GB       # –±–æ–ª—å—à–æ–π MemTable, —Ä–µ–¥–∫–∏–µ flushes
    compaction_threads = CPU / 2
    prefetch = aggressive
  elif available_ram > 512 MB:
    write_buffer_size = 128 MB     # —Å—Ä–µ–¥–Ω–∏–π MemTable
    compaction_threads = 2
    prefetch = moderate
  else:
    write_buffer_size = 16 MB      # –º–∞–ª–µ–Ω—å–∫–∏–π, —á–∞—Å—Ç—ã–µ flushes –Ω–∞ –¥–∏—Å–∫
    compaction_threads = 1
    prefetch = none, rely on mmap
```

–ë–æ–ª—å—à–µ RAM ‚Üí –±–æ–ª—å—à–µ batch ‚Üí –º–µ–Ω—å—à–µ I/O ‚Üí –±—ã—Å—Ç—Ä–µ–µ.
–ú–µ–Ω—å—à–µ RAM ‚Üí –º–µ–ª–∫–∏–µ batch ‚Üí –±–æ–ª—å—à–µ I/O –Ω–æ –Ω–µ OOM.

### CPU –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º

`rayon` (—É–∂–µ –≤ Cargo.toml) –¥–∞—ë—Ç data parallelism. –•–æ—Ä–æ—à–æ –ø–∞—Ä–∞–ª–ª–µ–ª—è—Ç—Å—è:

- **Analysis** (—Ñ–∞–π–ª ‚Üí —Å–µ–≥–º–µ–Ω—Ç) ‚Äî embarrassingly parallel, –Ω–µ—Ç shared state
- **Query scan** (–∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ) ‚Äî embarrassingly parallel
- **Compaction** (–∫–∞–∂–¥—ã–π shard –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ) ‚Äî embarrassingly parallel
- **Adjacency build** (partition by source node hash) ‚Äî parallel merge-sort

–ü–ª–æ—Ö–æ –ø–∞—Ä–∞–ª–ª–µ–ª—è—Ç—Å—è:
- Cross-shard enrichment ‚Äî –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É —à–∞—Ä–¥–∞–º–∏
- Manifest update ‚Äî single writer (–Ω–æ –±—ã—Å—Ç—Ä—ã–π)

Processing pipeline:
```
[File Queue] ‚Üí N workers (analysis) ‚Üí [Segment Queue] ‚Üí M workers (compaction)
                                                       ‚Üí K workers (query serving)
```

---

## 8. –ò–Ω–¥–µ–∫—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –¢—Ä–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –ø–æ–∏—Å–∫–∞

| –ü–∞—Ç—Ç–µ—Ä–Ω | –ü—Ä–∏–º–µ—Ä | –¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ |
|---------|--------|-----------|
| Point lookup | `getNode(semanticId)` | O(1), –ø–æ hash u128 |
| Attribute search | `queryNodes({type: "FUNCTION", name: "handleAuth"})` | Exact match –ø–æ –ø–æ–ª—è–º |
| Substring search | `queryNodes({name: contains("auth")})` | –ü–æ–∏—Å–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ |

### 1. Point lookup: SemanticID ‚Üí node

SemanticID = deterministic u128 hash (BLAKE3). –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π key-value lookup.

**–î–≤–∞ —Ä–µ–∂–∏–º–∞ (write ‚Üí read optimized):**

| | Bloom filter only | + Global index |
|---|---|---|
| –ö–æ–≥–¥–∞ | Write-heavy (Level 0, —Å–≤–µ–∂–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã) | Read-heavy (post-compaction) |
| RAM | ~1.6 MB (–≤–µ—Å—å –≥—Ä–∞—Ñ 1.3M –Ω–æ–¥) | +31 MB |
| Point lookup | ~–º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã | ~–Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã |
| –°—Ç—Ä–æ–∏—Ç—Å—è | –°—Ä–∞–∑—É –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ | –í —Ñ–æ–Ω–µ –ø—Ä–∏ compaction |

**Bloom filter** ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, 10 bits/key = 1% false positive rate.
–î–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ 1000 –Ω–æ–¥ = 1.2 KB. –û—Ç–≤–µ—Ç: "—Ç–æ—á–Ω–æ –Ω–µ—Ç" (skip segment) –∏–ª–∏ "–º–æ–∂–µ—Ç –±—ã—Ç—å" (check segment).

```
getNode(0xAB12):
  for segment in segments:
    if !segment.bloom.may_contain(0xAB12):
      continue                      # skip, 0 I/O (–Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã)
    return segment.binary_search(0xAB12)  # O(log k)
```

**Global index** (–ø–æ—Å–ª–µ compaction):
```
sorted array in mmap: [(node_id, segment_id, offset)]
1.3M –Ω–æ–¥ √ó 24 bytes = 31 MB

getNode(0xAB12):
  binary_search(global_index, 0xAB12) ‚Üí segment_42, offset 17  # O(log N), ~20 comparisons
```

### 2. Attribute search: per-segment inverted index

**Inverted index** = –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ term ‚Üí list of offsets (posting list).

```
Segment shard_auth.seg:
  columns:
    id:   [0xAB12, 0xCD34, 0xEF56, ...]
    type: [FUNCTION, VARIABLE, CALL, ...]
    name: [handleAuth, token, handleAuth(), ...]

  inverted_index:
    name:
      "handleAuth" ‚Üí [0, 2]     # offsets –≤ columns
      "token"      ‚Üí [1]
    type:
      "FUNCTION"   ‚Üí [0]
      "VARIABLE"   ‚Üí [1]
      "CALL"       ‚Üí [2]
```

**Query flow:**
```
queryNodes({type: "FUNCTION", name: "handleAuth"}):
  1. Manifest stats: –∫–∞–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç type=FUNCTION?
     ‚Üí skip –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
  2. Per-segment inverted index:
     ‚Üí type["FUNCTION"] ‚à© name["handleAuth"] = [0]
  3. Load full record at offset [0]
```

**Tradeoff inverted index:**
- Cost: write amplification (+5 –∑–∞–ø–∏—Å–µ–π/–Ω–æ–¥–∞), +20-40% storage, –¥–æ—Ä–æ–≥–æ–π merge –ø—Ä–∏ compaction
- Benefit: O(1) exact match vs O(n) scan, intersection –¥–ª—è multi-field queries

**–ö–ª—é—á–µ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ: inverted index —Å—Ç—Ä–æ–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ compaction (Level 1+).**

–ù–∞ Level 0 (—Å–≤–µ–∂–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã, 500-2000 –Ω–æ–¥):
- Name column ~10-40 KB ‚Üí —Ü–µ–ª–∏–∫–æ–º –≤ L1 cache
- Columnar scan = –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã, inverted index –Ω–µ –Ω—É–∂–µ–Ω
- Write path: –Ω–æ–ª—å overhead –æ—Ç –∏–Ω–¥–µ–∫—Å–æ–≤

–ù–∞ Level 1+ (compacted, 50-100K+ –Ω–æ–¥):
- Inverted index —Å—Ç—Ä–æ–∏—Ç—Å—è –≤ —Ñ–æ–Ω–µ –ø—Ä–∏ compaction
- Read path: O(1) —á–µ—Ä–µ–∑ index

### 3. Substring/prefix search

–î–ª—è exact match ‚Äî inverted index. –î–ª—è –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:

**–û–ø—Ü–∏–∏:**
- **Trigram index** (–∫–∞–∫ PostgreSQL pg_trgm): "handleAuth" ‚Üí trigrams ["han","and","ndl",...], intersection —Å—É–∂–∞–µ—Ç candidates, verify exact
- **FST (Finite State Transducer)** ‚Äî Tantivy/Lucene –ø–æ–¥—Ö–æ–¥, Rust –∫—Ä–µ–π—Ç `fst`. Compact term dictionary, prefix/fuzzy
- **MVP: columnar scan + SIMD** ‚Äî name column –∫–æ–º–ø–∞–∫—Ç–Ω–∞, SIMD scan 1000 —Å—Ç—Ä–æ–∫ = –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥—ã. Trigram/FST –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–∑–∂–µ

### 4. Metadata search

`queryNodes({metadata.async: true})` ‚Äî –ø–æ–∏—Å–∫ –ø–æ –≤–ª–æ–∂–µ–Ω–Ω—ã–º –ø–æ–ª—è–º metadata JSON.

–¢–µ –∂–µ –æ–ø—Ü–∏–∏: columnar scan –¥–ª—è –º–µ–ª–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤, inverted index –ø–æ promoted metadata fields –ø—Ä–∏ compaction.

### –ò—Ç–æ–≥–æ: –∏–Ω–¥–µ–∫—Å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ per-segment

```
Per-segment:
  ‚îú‚îÄ‚îÄ bloom_filter          # point lookup: ID in segment? O(1), —Å—Ç—Ä–æ–∏—Ç—Å—è –°–†–ê–ó–£
  ‚îú‚îÄ‚îÄ sorted_id_column      # point lookup: binary search O(log k)
  ‚îú‚îÄ‚îÄ columnar_data         # attr search: scan –¥–ª—è –º–µ–ª–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
  ‚îî‚îÄ‚îÄ (post-compaction):
      ‚îú‚îÄ‚îÄ inverted_index    # exact attr search: term ‚Üí offsets O(1)
      ‚îÇ   ‚îú‚îÄ‚îÄ by_type
      ‚îÇ   ‚îú‚îÄ‚îÄ by_name
      ‚îÇ   ‚îî‚îÄ‚îÄ by_file
      ‚îî‚îÄ‚îÄ trigram_index     # substring search (optional, later)

Global (post-compaction):
  ‚îú‚îÄ‚îÄ id_index (mmap)       # node_id ‚Üí (segment, offset), 31 MB for 1.3M nodes
  ‚îî‚îÄ‚îÄ manifest stats        # query planning: skip irrelevant segments
```

**Rust libraries:** `fst` (FST), `tantivy` (search components), `bitvec` (bitmaps), `blake3` (hashing)

---

## 9. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: RFDB v2 Architecture

### Storage layout

```
.rfdb/
‚îú‚îÄ‚îÄ current.json                    # Atomic pointer ‚Üí latest snapshot
‚îÇ
‚îú‚îÄ‚îÄ snapshots/
‚îÇ   ‚îú‚îÄ‚îÄ snap-001.json              # Manifest: list of active segments + stats
‚îÇ   ‚îú‚îÄ‚îÄ snap-002.json              # After re-analysis of 1 file
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ segments/
‚îÇ   ‚îú‚îÄ‚îÄ nodes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ owner_{hash1}.seg      # Nodes from src/app.ts (columnar, immutable)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ owner_{hash2}.seg      # Nodes from src/auth.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îî‚îÄ‚îÄ edges/
‚îÇ       ‚îú‚îÄ‚îÄ owner_{hash1}.seg      # Edges owned by src/app.ts
‚îÇ       ‚îú‚îÄ‚îÄ owner_{hash2}.seg      # Edges owned by src/auth.ts
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îÇ   # Adjacency = –ù–ï –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–π. Edge segments –≤ —à–∞—Ä–¥–∞—Ö —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç
‚îÇ   # (src, dst, type). Bloom filter per shard –¥–ª—è neighbors() queries.
‚îÇ   # Tombstones –ø—Ä–∏ re-analysis, compaction —á–∏—Å—Ç–∏—Ç.
‚îÇ
‚îî‚îÄ‚îÄ gc/                            # Deleted segments, pending cleanup
    ‚îú‚îÄ‚îÄ owner_{hash1}_v1.seg       # Old version, safe to delete after readers finish
    ‚îî‚îÄ‚îÄ ...
```

### Write flow

```
analyzeFile("src/app.ts"):
  1. Write nodes/owner_{hash}.seg   (immutable columnar)
  2. Write edges/owner_{hash}.seg   (immutable columnar)
  3. New snapshot: snap-002 = snap-001 + {add: [hash], remove: [hash_old]}
  4. Atomic rename current.json ‚Üí snap-002
  5. Old segments ‚Üí gc/
```

### Delete flow (re-analysis)

```
reanalyzeFile("src/app.ts"):
  1. Mark old owner_{hash} segments as deleted in new snapshot
  2. Create new segments
  3. Rebuild adjacency (only changed edges)
  4. Atomic snapshot swap
  // O(nodes_in_file), NOT O(total_graph)
```

### Query flow

```
queryNodes({type: "FUNCTION", file: "src/app.ts"}):
  1. Read current.json ‚Üí snapshot
  2. Manifest: owner_{hash}.seg has FUNCTION nodes, file=src/app.ts
  3. mmap segment, scan columnar data
  4. Return results

neighbors(nodeId):
  1. Binary search forward.seg for nodeId
  2. Return matching edges
```

### RAM budget

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –†–∞–∑–º–µ—Ä | –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è —Å |
|-----------|--------|-----------------|
| Manifest (snapshot JSON) | ~500KB | Segment count |
| Write buffer (current batch) | ~10-50MB | Batch size |
| OS page cache | Auto-managed | Hot data only |
| **Total app RAM** | **<100 MB** | **–ù–∏—á–µ–≥–æ** |

---

## 10. –û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã

### ‚úÖ Enrichment ownership ‚Üí –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —à–∞—Ä–¥—ã + incremental re-enrichment

**–†–µ—à–µ–Ω–∏–µ: enricher = –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —à–∞—Ä–¥ —Å ownership tracking.**

Enrichment edges —Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö —à–∞—Ä–¥–∞—Ö per enricher:
```
Shards:
  src/controllers/auth/           # analysis shard (—Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã)
  src/services/payment/           # analysis shard
  __enrichment__/imports/         # –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π shard ‚Äî ImportExportLinker
  __enrichment__/mount-points/    # –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π shard ‚Äî MountPointResolver
  __enrichment__/http-connections/ # –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π shard ‚Äî HTTPConnectionEnricher
```

–ö–∞–∂–¥—ã–π enrichment edge –Ω–µ—Å—ë—Ç `_owner` = –∏–º—è enricher-–∞.

**Incremental re-enrichment –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞:**

```
Re-analysis —Ñ–∞–π–ª–∞ X:
  1. Re-analyze ‚Üí new_nodes, new_edges
  2. delta = diff(old_nodes + old_edges, new_nodes + new_edges)
  3. if delta == ‚àÖ ‚Üí done
  4. changed_node_ids = endpoints(delta)
  5. –î–ª—è –∫–∞–∂–¥–æ–≥–æ enricher —É –∫–æ–≥–æ depends_on_node_types ‚à© —Ç–∏–ø—ã changed nodes ‚â† ‚àÖ:
     a. SELECT enrichment edges WHERE (src OR dst) IN changed_node_ids AND _owner = enricher
     b. DELETE —ç—Ç–∏ edges
     c. Re-enrich –¢–û–õ–¨–ö–û changed_node_ids (–Ω–µ –≤–µ—Å—å –≥—Ä–∞—Ñ!)
  6. –¢—Ä–∞–Ω–∑–∏—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ: –µ—Å–ª–∏ enrichment —Å–æ–∑–¥–∞–ª –Ω–æ–≤—ã–µ edges ‚Üí
     –∏—Ö endpoints —Ç–æ–∂–µ affected ‚Üí propagate (—Å depth limit)
```

**–ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–Ω—Ü–∏–ø:** –¥–µ–ª—å—Ç–∞ –Ω–æ–¥ –ù–ï–î–û–°–¢–ê–¢–û–ß–ù–ê. –ù—É–∂–Ω–∞ –¥–µ–ª—å—Ç–∞ –Ω–æ–¥ + edges.
–§—É–Ω–∫—Ü–∏—è —Å —Ç–µ–º –∂–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º ID, –Ω–æ –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º–∏ CALLS edges ‚Äî –∑–∞—Ç—Ä–æ–Ω—É—Ç–∞.

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ enricher –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ (–æ—Ç–¥–µ–ª—å–Ω—ã–π research):**

–°–µ–π—á–∞—Å enricher = –º–æ–Ω–æ–ª–∏—Ç (`execute()` —Å–∞–º –∏—â–µ—Ç + —Å–∞–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç). –ù—É–∂–Ω–∞ –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è:

**Selector** (–¥–µ–∫–ª–∞—Ä–∞—Ç–∏–≤–Ω—ã–π, –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –≤–ª–∞–¥–µ–µ—Ç):
```typescript
get inputs(): EnricherInputSpec {
  return {
    sources: [
      { type: 'http:request', role: 'request' },
      { type: 'http:route', role: 'route' },
    ]
  };
}
```

**Processor** (—á–∏—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞, –ø–ª–∞–≥–∏–Ω –≤–ª–∞–¥–µ–µ—Ç):
```typescript
async process(inputs: GroupedNodes): EnricherOutput {
  // –¢–æ–ª—å–∫–æ –ª–æ–≥–∏–∫–∞ –º–∞—Ç—á–∏–Ω–≥–∞, –±–µ–∑ queryNodes
  // –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç edges, –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç addEdge –Ω–∞–ø—Ä—è–º—É—é
  return { edges };
}
```

–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä:
- Full run: –ø–æ–¥–∞—ë—Ç –í–°–ï –Ω–æ–¥—ã matching input types
- Incremental: –ø–æ–¥–∞—ë—Ç –¢–û–õ–¨–ö–û changed nodes + counterpart (–≤—Ç–æ—Ä–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ join)
- –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç edges —Å `_owner` tracking

**–î–≤–∞ —Ç–∏–ø–∞ enrichers:**

| –¢–∏–ø | Selector | Incremental | –ü—Ä–∏–º–µ—Ä |
|-----|----------|-------------|--------|
| **Join** | 2+ node types, –º–∞—Ç—á–∏–Ω–≥ | –¢—Ä–∏–≤–∏–∞–ª–µ–Ω: –ø–æ–¥–∞—Ç—å changed √ó all_other | HTTPConnectionEnricher, ImportExportLinker |
| **Traversal** | seed nodes + graph reader | –û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–∞—ë—Ç seeds –∏–∑ –¥–µ–ª—å—Ç—ã | MountPointResolver, ClosureCaptureEnricher |

–í –æ–±–æ–∏—Ö —Å–ª—É—á–∞—è—Ö enricher –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç `addEdge` –Ω–∞–ø—Ä—è–º—É—é ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç edges,
–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å ownership. –≠—Ç–æ –¥–∞—ë—Ç –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π.

**TODO:** –æ—Ç–¥–µ–ª—å–Ω—ã–π research –ø–æ –ø–µ—Ä–µ–æ—Å–º—ã—Å–ª–µ–Ω–∏—é –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –¥–ª—è incremental updates.

### üü° Compaction: –∫–æ–≥–¥–∞ –∏ –∑–∞—á–µ–º?

**–í–∞–¥–∏–º**: "–ß—Ç–æ –¥–∞—ë—Ç compaction? –ó–∞—á–µ–º –Ω–∞–º –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã?"

**–û—Ç–≤–µ—Ç**: –î–ª—è query performance –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ (mmap + manifest pruning). –ù–æ:
- 2500 files √ó 2 (nodes+edges) = 5000 segments. File descriptors.
- macOS ulimit -n = 256 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –ù—É–∂–Ω–æ –ø–æ–¥–Ω–∏–º–∞—Ç—å –∏–ª–∏ lazy mmap.
- Compaction –Ω—É–∂–µ–Ω –¥–ª—è —á–∏—Å—Ç–∫–∏ gc/ (—É–¥–∞–ª—ë–Ω–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã) –∏ merge –º–µ–ª–∫–∏—Ö —Ñ–∞–π–ª–æ–≤

**–†–µ—à–µ–Ω–∏–µ**: –Ω–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç. Blue/green –≤ —Ñ–æ–Ω–µ: build new merged segment ‚Üí swap in snapshot ‚Üí delete old. –°–Ω–∞—á–∞–ª–∞ "–ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç".

### üü° Index rebuilds

**–í–∞–¥–∏–º**: "–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç ‚Äî —á—Ç–æ–±—ã –ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–ª–æ. –í —Ñ–æ–Ω–µ —Å–µ—Ä–≤–µ—Ä –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç."

**–†–µ—à–µ–Ω–∏–µ**: Blue/green –ø–æ–¥—Ö–æ–¥:
1. Queries —Ä–∞–±–æ—Ç–∞—é—Ç —Å —Ç–µ–∫—É—â–∏–º–∏ indexes (sorted mmap)
2. Background thread —Å—Ç—Ä–æ–∏—Ç –Ω–æ–≤—ã–µ (–ø–æ—Å–ª–µ compaction)
3. Atomic swap –∫–æ–≥–¥–∞ –≥–æ—Ç–æ–≤—ã

### üü¢ WAL

**–í–∞–¥–∏–º**: "WAL –∏–∑–±—ã—Ç–æ—á–µ–Ω. Re-analyze = recovery."

**–†–µ—à–µ–Ω–∏–µ**: –Ω–µ—Ç WAL –≤ v2. –ï—Å–ª–∏ crash ‚Äî re-analyze. Segment files immutable, —Ç–∞–∫ —á—Ç–æ partial writes = corrupted segment ‚Üí —É–¥–∞–ª–∏—Ç—å –∏ re-analyze —Ç–æ—Ç —Ñ–∞–π–ª.

### ‚úÖ Adjacency rebuild ‚Üí LSM –≤ —à–∞—Ä–¥–∞—Ö, –±–µ–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–ª–æ—è

**–†–µ—à–µ–Ω–∏–µ:** adjacency –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–π (forward.seg/reverse.seg), –∞ —Ç–∞ –∂–µ —à–∞—Ä–¥–æ–≤–∞—è LSM –º–µ—Ö–∞–Ω–∏–∫–∞.

Edge segments –≤ —à–∞—Ä–¥–∞—Ö —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç (src, dst, type) ‚Äî —ç—Ç–æ –∏ –µ—Å—Ç—å adjacency data.

**Re-analysis:**
1. Tombstones –Ω–∞ —É–¥–∞–ª—ë–Ω–Ω—ã–µ edges –≤ —à–∞—Ä–¥–µ
2. –ù–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç —Å –Ω–æ–≤—ã–º–∏ edges
3. O(changed_edges), NOT O(total_edges)

**Query `neighbors(nodeId)`:**
1. Bloom filter: –≤ –∫–∞–∫–∏—Ö —à–∞—Ä–¥–∞—Ö –º–æ–≥—É—Ç –±—ã—Ç—å edges —Å src=nodeId?
2. Scan matching —à–∞—Ä–¥—ã, skip tombstones
3. Return results

**Compaction:** merge —à–∞—Ä–¥—ã, –≤—ã–∫–∏–Ω—É—Ç—å tombstones ‚Üí —á–∏—Å—Ç—ã–π —Å–µ–≥–º–µ–Ω—Ç, –±—ã—Å—Ç—Ä—ã–µ reads.

–ù–∏–∫–∞–∫–æ–≥–æ special case ‚Äî –æ–¥–Ω–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (—à–∞—Ä–¥—ã + bloom + LSM + compaction) –¥–ª—è –≤—Å–µ–≥–æ.

### üü° –§–æ—Ä–º–∞—Ç snapshot manifest

–ß—Ç–æ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å manifest –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ query planning:
```json
{
  "version": 42,
  "segments": {
    "nodes/owner_a1b2c3.seg": {
      "owner_file": "src/app.ts",
      "node_count": 520,
      "node_types": ["FUNCTION", "VARIABLE", "CALL", "SCOPE"],
      "has_metadata_fields": ["object", "method", "async"],
      "min_id": "0x001...",
      "max_id": "0xFFF...",
      "created_at": "2026-02-10T12:00:00Z",
      "phase": "analysis"  // or "enrichment"
    }
  },
  "deleted_segments": ["nodes/owner_a1b2c3_v1.seg"],
  "adjacency_version": 41
}
```

### ‚úÖ Small files problem ‚Üí –°—Ç—É–ø–µ–Ω—á–∞—Ç–æ–µ —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ

**–†–µ—à–µ–Ω–∏–µ: –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ directory-based —à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ.**

Shard = –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è. –§–∞–π–ª—ã –≤ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ —Ç–µ—Å–Ω–æ —Å–≤—è–∑–∞–Ω—ã (–±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ edges ‚Äî intra-shard), –Ω–∞—Ä—É–∂—É —Ç–æ—Ä—á–∏—Ç API/interface (–Ω–µ–º–Ω–æ–≥–æ cross-shard edges).

**–°—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π split/merge:**
- Shard —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>N –Ω–æ–¥, –ø–æ—Ä–æ–≥ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤) ‚Üí split –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º, –≤–ø–ª–æ—Ç—å –¥–æ 1 —Ñ–∞–π–ª–∞
- Shard —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π (–º–∞–ª–æ –Ω–æ–¥) ‚Üí merge —Å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π
- –î–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã = –¥–µ—Ä–µ–≤–æ —à–∞—Ä–¥–æ–≤, –≥—Ä–∞–Ω–∏—Ü–∞ –¥–≤–∏–≥–∞–µ—Ç—Å—è –≤–≤–µ—Ä—Ö-–≤–Ω–∏–∑ –ø–æ –¥–µ—Ä–µ–≤—É
- –û–ø–µ—Ä–∞—Ü–∏—è –¥–µ—à—ë–≤–∞—è: –ø–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å 2 —Å–µ–≥–º–µ–Ω—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç—å manifest

**Threshold –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π:**
- –°–µ—Ä–≤–µ—Ä 512 GB RAM ‚Üí –∫—Ä—É–ø–Ω—ã–µ —à–∞—Ä–¥—ã (–º–µ–Ω—å—à–µ overhead –Ω–∞ boundary edges)
- –ù–æ—É—Ç–±—É–∫ 8 GB ‚Üí –º–µ–ª–∫–∏–µ —à–∞—Ä–¥—ã (–º–µ–Ω—å—à–µ RAM per shard)

**Enrichment edges:**
- Intra-shard enrichment ‚Üí —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ —Å–µ–≥–º–µ–Ω—Ç–µ —à–∞—Ä–¥–∞
- Cross-shard enrichment (–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä ‚Üí —Å–µ—Ä–≤–∏—Å –≤ –¥—Ä—É–≥–æ–π –ø–∞–ø–∫–µ) ‚Üí –æ—Ç–¥–µ–ª—å–Ω—ã–π boundary edges index, –∏—Ö –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ –º–∞–ª–æ

**Re-analysis:** –∏–∑–º–µ–Ω–∏–ª—Å—è —Ñ–∞–π–ª ‚Üí –ø–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ–≥–æ shard, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –Ω–µ —Ç—Ä–æ–≥–∞—é—Ç—Å—è

**–ò–µ—Ä–∞—Ä—Ö–∏—è:**
```
src/                          # mega-shard (cross-module queries)
‚îú‚îÄ‚îÄ controllers/auth/         # shard ‚Äî 15 —Ñ–∞–π–ª–æ–≤, —Ç–µ—Å–Ω–æ —Å–≤—è–∑–∞–Ω—ã
‚îú‚îÄ‚îÄ controllers/orders/       # shard
‚îú‚îÄ‚îÄ services/payment/         # shard (–±–æ–ª—å—à–æ–π ‚Üí –º–æ–∂–µ—Ç split –Ω–∞ –ø–æ–¥–ø–∞–ø–∫–∏)
‚îî‚îÄ‚îÄ utils/                    # shard (–º–∞–ª–µ–Ω—å–∫–∏–π ‚Üí –º–æ–∂–µ—Ç merge –≤–≤–µ—Ä—Ö)
```

**Query:** `neighbors(nodeId)` ‚Üí —Å–Ω–∞—á–∞–ª–∞ local shard (–±—ã—Å—Ç—Ä–æ), –ø–æ—Ç–æ–º boundary index –¥–ª—è cross-shard edges

---

## 11. –†–µ—à—ë–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã

| –í–æ–ø—Ä–æ—Å | –†–µ—à–µ–Ω–∏–µ |
|--------|---------|
| Columnar vs row-oriented | **Columnar** ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –¥–ª—è –Ω–∞—à–µ–≥–æ filtering-based query pattern |
| Global vs per-segment strings | **Per-segment** ‚Äî locality –¥–ª—è attr search |
| WAL | **–ù–µ—Ç** ‚Äî re-analyze = recovery |
| Index rebuild strategy | **Blue/green** –≤ —Ñ–æ–Ω–µ, "–ø—Ä–æ—Å—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç" —Å–Ω–∞—á–∞–ª–∞ |
| Edge ownership model | **Source-tagged** (–µ–¥–∏–Ω–æ–≥–ª–∞—Å–Ω—ã–π –º–∏—Ä–æ–≤–æ–π –æ–ø—ã—Ç) |
| Compaction priority | **–ù–∏–∑–∫–∏–π** ‚Äî blue/green –≤ —Ñ–æ–Ω–µ, –Ω–µ –±–ª–æ–∫–µ—Ä |
| Small files / sharding | **–°—Ç—É–ø–µ–Ω—á–∞—Ç–æ–µ directory-based** ‚Äî shard=–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π split/merge –ø–æ —Ä–∞–∑–º–µ—Ä—É |
| Write/read mode | **LSM-style** ‚Äî write-optimized (append) ‚Üí read-optimized (sorted+indexed) —á–µ—Ä–µ–∑ background compaction |
| –ò–Ω–¥–µ–∫—Å—ã: –∫–æ–≥–¥–∞ —Å—Ç—Ä–æ–∏—Ç—å | **Bloom filter —Å—Ä–∞–∑—É** (–¥—ë—à–µ–≤–æ), **inverted index –ø—Ä–∏ compaction** (–¥–æ—Ä–æ–≥–æ, –≤ —Ñ–æ–Ω–µ) |
| Point lookup | **Bloom filter (L0)** ‚Üí **Global mmap index (post-compaction)** |
| Attr search | **Columnar scan (–º–µ–ª–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã)** ‚Üí **inverted index (compacted)** |
| Resource management | **Adaptive** ‚Äî write buffer, compaction threads, prefetch –∑–∞–≤—è–∑–∞–Ω—ã –Ω–∞ available RAM/CPU |
| Adjacency | **LSM –≤ —à–∞—Ä–¥–∞—Ö** ‚Äî –Ω–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Å–ª–æ–π, edges –≤ —à–∞—Ä–¥–∞—Ö —Å bloom + tombstones –ø—Ä–∏ re-analysis + compaction |
| Enrichment ownership | **–í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ —à–∞—Ä–¥—ã** per enricher + `_owner` –Ω–∞ edges + incremental re-enrichment –ø–æ –¥–µ–ª—å—Ç–µ |
| Enricher –∫–æ–Ω—Ç—Ä–∞–∫—Ç | **Selector/Processor split** ‚Äî –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç, enricher –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç, –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç addEdge –Ω–∞–ø—Ä—è–º—É—é |

---

## 12. –°—Å—ã–ª–∫–∏

### –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã
- [Incrementalizing Production CodeQL (ESEC/FSE 2023)](https://arxiv.org/pdf/2308.09660)
- [SourcetrailDB](https://github.com/CoatiSoftware/SourcetrailDB)
- [Flatgraph (Joern successor to OverflowDB)](https://github.com/joernio/flatgraph)

### Graph databases
- [NebulaGraph Storage Format v2.0](https://www.nebula-graph.io/posts/storage-format-in-nebula-graph-2.0)
- [TerminusDB Succinct Data Structures](https://terminusdb.com/blog/succinct-data-structures-for-modern-databases/)

### Social graph systems
- [TAO: Facebook's Distributed Data Store (USENIX)](https://www.usenix.org/system/files/conference/atc13/atc13-bronson.pdf)
- [LIquid: LinkedIn's Graph Database](https://www.linkedin.com/blog/engineering/graph-systems/liquid-the-soul-of-a-new-graph-database-part-1)

### Research
- [LiveGraph (VLDB 2020)](https://vldb.org/pvldb/vol13/p1020-zhu.pdf)
- [BACH: LSM-Tree Graph Storage (VLDB 2025)](https://www.vldb.org/pvldb/vol18/p1509-miao.pdf)
- [STINGER: Streaming Graph Data Structure](https://ieee-hpec.org/2012/index_htm_files/ediger.pdf)

### Table formats (Iceberg-like)
- [Apache Iceberg Spec](https://iceberg.apache.org/spec/)
- [Iceberg Metadata Explained](https://olake.io/blog/2025/10/03/iceberg-metadata/)
- [Iceberg vs Delta Lake vs Hudi](https://www.onehouse.ai/blog/apache-hudi-vs-delta-lake-vs-apache-iceberg-lakehouse-feature-comparison)
